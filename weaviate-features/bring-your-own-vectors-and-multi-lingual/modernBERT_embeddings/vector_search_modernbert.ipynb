{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9kcX2B_atc"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-features/bring-your-own-vectors-and-multi-lingual/modernBERT_embeddings/vector_search_modernbert.ipynb)\n",
        "\n",
        "![Cover image](vector_search_modernbert_cover_image.png)\n",
        "\n",
        "# Generating Embeddings for Vector Search with ModernBERT in Weaviate\n",
        "## A 100% open source recipe üßë‚Äçüç≥ üíö\n",
        "By Mary Newhauser, MLE @ Weaviate\n",
        "\n",
        "This is a code recipe that uses [Nomic AI](https://www.nomic.ai/)'s [modernbert-embed-base](https://huggingface.co/nomic-ai/modernbert-embed-base) model to generate text embeddings for machine learning papers, inserts them into [Weaviate](https://weaviate.io/) and performs similarity search over the documents.\n",
        "\n",
        "In this notebook, we accomplish the following:\n",
        "* Load and transform the [ML-ArXiv-Papers](https://huggingface.co/datasets/CShorten/ML-ArXiv-Papers) dataset\n",
        "* Generate text embeddings for a random sample of 100 articles using `sentence-transformers` and `modernbert-embed-base`\n",
        "* Perform a basic similarity search over the dataset\n",
        "\n",
        "## About ModernBERT\n",
        "[ModernBERT](https://arxiv.org/abs/2412.13663) is the biggest improvement in years to the [BERT](https://arxiv.org/abs/1810.04805) model. ModernBERT features:\n",
        "* 16x longer sequence length\n",
        "* Faster inference\n",
        "* SOTA performance across tasks like classification and retrieval\n",
        "\n",
        "For more information, check out Hugging Face's ModernBERT [blog post](https://huggingface.co/blog/modernbert)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "49AguLS_izgn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Until the next transformers release, doing so requires installing transformers from main\n",
        "%pip install git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "u076oUSF_YUG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install sentence-transformers\n",
        "%pip install datasets\n",
        "%pip install -U weaviate-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q2F9RUmR8Wj"
      },
      "source": [
        "## Load and transform dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x6lmOYEPm_-7"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"CShorten/ML-ArXiv-Papers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T75_q7iunTOS"
      },
      "outputs": [],
      "source": [
        "# Keep only \"title\" and \"abstract\" columns in train set\n",
        "train_ds = ds[\"train\"].select_columns([\"title\", \"abstract\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CzfutYG0Qm1"
      },
      "source": [
        "The original dataset contains over ~100k titles and abstracts for ML papers from arXiv. For this demo, we'll just take a random sample of 100 papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoKLdyYdoMu2",
        "outputId": "1927e16e-5283-4748-b846-6c261c2094cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows: 100\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Set seed\n",
        "random.seed(42)\n",
        "\n",
        "# Shuffle the dataset and select the first 100 rows\n",
        "subset_ds = train_ds.shuffle(seed=42).select(range(100))\n",
        "\n",
        "# Concatenate abstract and titles\n",
        "def combine_text(row):\n",
        "    row[\"text\"] = row[\"abstract\"] + \" \" + row[\"title\"]\n",
        "    return row\n",
        "\n",
        "# Apply function to entire dataset\n",
        "subset_ds = subset_ds.map(combine_text)\n",
        "\n",
        "# Print number of rows\n",
        "print(f\"Number of rows: {len(subset_ds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHmxwEaK0cZR"
      },
      "source": [
        "## Generate embeddings with `modernbert-embed-base`\n",
        "We'll use the `sentence-transformers` library to load and embed the concatenated titles and abstracts with the `modernbert-embed-base` embedding model, adding them to their own column in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5hoxESKCpS6j"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the SentenceTransformer model\n",
        "model = SentenceTransformer(\"nomic-ai/modernbert-embed-base\")\n",
        "\n",
        "# Function to generate embeddings for a single text\n",
        "def generate_embeddings(example):\n",
        "    example[\"embeddings\"] = model.encode(example[\"text\"])\n",
        "    return example\n",
        "\n",
        "# Apply the function to the dataset using map\n",
        "embeddings_ds = subset_ds.map(generate_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ZIRpZF03fT"
      },
      "source": [
        "Next, we'll convert the dataset to a `pandas` `DataFrame` for insertion into Weaviate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CwjknzYMp8O4",
        "outputId": "e7625e8f-d891-4152-8aa1-e11c10a97cec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Binacox: automatic cut-point detection in high-dimensional Cox model\\n  with applications in genetics\",\n          \"Dynamic Narrowing of VAE Bottlenecks Using GECO and L0 Regularization\",\n          \"Taxonomy of Saliency Metrics for Channel Pruning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"  We introduce the binacox, a prognostic method to deal with the problem of\\ndetecting multiple cut-points per features in a multivariate setting where a\\nlarge number of continuous features are available. The method is based on the\\nCox model and combines one-hot encoding with the binarsity penalty, which uses\\ntotal-variation regularization together with an extra linear constraint, and\\nenables feature selection. Original nonasymptotic oracle inequalities for\\nprediction (in terms of Kullback-Leibler divergence) and estimation with a fast\\nrate of convergence are established. The statistical performance of the method\\nis examined in an extensive Monte Carlo simulation study, and then illustrated\\non three publicly available genetic cancer datasets. On these high-dimensional\\ndatasets, our proposed method significantly outperforms state-of-the-art\\nsurvival models regarding risk prediction in terms of the C-index, with a\\ncomputing time orders of magnitude faster. In addition, it provides powerful\\ninterpretability from a clinical perspective by automatically pinpointing\\nsignificant cut-points in relevant variables.\\n\",\n          \"  When designing variational autoencoders (VAEs) or other types of latent space\\nmodels, the dimensionality of the latent space is typically defined upfront. In\\nthis process, it is possible that the number of dimensions is under- or\\noverprovisioned for the application at hand. In case the dimensionality is not\\npredefined, this parameter is usually determined using time- and\\nresource-consuming cross-validation. For these reasons we have developed a\\ntechnique to shrink the latent space dimensionality of VAEs automatically and\\non-the-fly during training using Generalized ELBO with Constrained Optimization\\n(GECO) and the $L_0$-Augment-REINFORCE-Merge ($L_0$-ARM) gradient estimator.\\nThe GECO optimizer ensures that we are not violating a predefined upper bound\\non the reconstruction error. This paper presents the algorithmic details of our\\nmethod along with experimental results on five different datasets. We find that\\nour training procedure is stable and that the latent space can be pruned\\neffectively without violating the GECO constraints.\\n\",\n          \"  Pruning unimportant parameters can allow deep neural networks (DNNs) to\\nreduce their heavy computation and memory requirements. A saliency metric\\nestimates which parameters can be safely pruned with little impact on the\\nclassification performance of the DNN. Many saliency metrics have been\\nproposed, each within the context of a wider pruning algorithm. The result is\\nthat it is difficult to separate the effectiveness of the saliency metric from\\nthe wider pruning algorithm that surrounds it. Similar-looking saliency metrics\\ncan yield very different results because of apparently minor design choices. We\\npropose a taxonomy of saliency metrics based on four mostly-orthogonal\\nprincipal components. We show that a broad range of metrics from the pruning\\nliterature can be grouped according to these components. Our taxonomy not only\\nserves as a guide to prior work, but allows us to construct new saliency\\nmetrics by exploring novel combinations of our taxonomic components. We perform\\nan in-depth experimental investigation of more than 300 saliency metrics. Our\\nresults provide decisive answers to open research questions, and demonstrate\\nthe importance of reduction and scaling when pruning groups of weights. We find\\nthat some of our constructed metrics can outperform the best existing\\nstate-of-the-art metrics for convolutional neural network channel pruning.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"  We introduce the binacox, a prognostic method to deal with the problem of\\ndetecting multiple cut-points per features in a multivariate setting where a\\nlarge number of continuous features are available. The method is based on the\\nCox model and combines one-hot encoding with the binarsity penalty, which uses\\ntotal-variation regularization together with an extra linear constraint, and\\nenables feature selection. Original nonasymptotic oracle inequalities for\\nprediction (in terms of Kullback-Leibler divergence) and estimation with a fast\\nrate of convergence are established. The statistical performance of the method\\nis examined in an extensive Monte Carlo simulation study, and then illustrated\\non three publicly available genetic cancer datasets. On these high-dimensional\\ndatasets, our proposed method significantly outperforms state-of-the-art\\nsurvival models regarding risk prediction in terms of the C-index, with a\\ncomputing time orders of magnitude faster. In addition, it provides powerful\\ninterpretability from a clinical perspective by automatically pinpointing\\nsignificant cut-points in relevant variables.\\n Binacox: automatic cut-point detection in high-dimensional Cox model\\n  with applications in genetics\",\n          \"  When designing variational autoencoders (VAEs) or other types of latent space\\nmodels, the dimensionality of the latent space is typically defined upfront. In\\nthis process, it is possible that the number of dimensions is under- or\\noverprovisioned for the application at hand. In case the dimensionality is not\\npredefined, this parameter is usually determined using time- and\\nresource-consuming cross-validation. For these reasons we have developed a\\ntechnique to shrink the latent space dimensionality of VAEs automatically and\\non-the-fly during training using Generalized ELBO with Constrained Optimization\\n(GECO) and the $L_0$-Augment-REINFORCE-Merge ($L_0$-ARM) gradient estimator.\\nThe GECO optimizer ensures that we are not violating a predefined upper bound\\non the reconstruction error. This paper presents the algorithmic details of our\\nmethod along with experimental results on five different datasets. We find that\\nour training procedure is stable and that the latent space can be pruned\\neffectively without violating the GECO constraints.\\n Dynamic Narrowing of VAE Bottlenecks Using GECO and L0 Regularization\",\n          \"  Pruning unimportant parameters can allow deep neural networks (DNNs) to\\nreduce their heavy computation and memory requirements. A saliency metric\\nestimates which parameters can be safely pruned with little impact on the\\nclassification performance of the DNN. Many saliency metrics have been\\nproposed, each within the context of a wider pruning algorithm. The result is\\nthat it is difficult to separate the effectiveness of the saliency metric from\\nthe wider pruning algorithm that surrounds it. Similar-looking saliency metrics\\ncan yield very different results because of apparently minor design choices. We\\npropose a taxonomy of saliency metrics based on four mostly-orthogonal\\nprincipal components. We show that a broad range of metrics from the pruning\\nliterature can be grouped according to these components. Our taxonomy not only\\nserves as a guide to prior work, but allows us to construct new saliency\\nmetrics by exploring novel combinations of our taxonomic components. We perform\\nan in-depth experimental investigation of more than 300 saliency metrics. Our\\nresults provide decisive answers to open research questions, and demonstrate\\nthe importance of reduction and scaling when pruning groups of weights. We find\\nthat some of our constructed metrics can outperform the best existing\\nstate-of-the-art metrics for convolutional neural network channel pruning.\\n Taxonomy of Saliency Metrics for Channel Pruning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embeddings\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c0504f45-f640-4049-8da8-4da304561afc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>text</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Epsilon Consistent Mixup: Structural Regulariz...</td>\n",
              "      <td>In this paper we propose $\\epsilon$-Consiste...</td>\n",
              "      <td>In this paper we propose $\\epsilon$-Consiste...</td>\n",
              "      <td>[0.004646845, -0.012128952, -0.019156834, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Particle Graph Autoencoders and Differentiable...</td>\n",
              "      <td>Autoencoders have useful applications in hig...</td>\n",
              "      <td>Autoencoders have useful applications in hig...</td>\n",
              "      <td>[-0.036488354, 0.013384212, 0.007417859, 0.009...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Probabilistic DAG Search</td>\n",
              "      <td>Exciting contemporary machine learning probl...</td>\n",
              "      <td>Exciting contemporary machine learning probl...</td>\n",
              "      <td>[0.021119291, -0.03755111, -0.026112985, -0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Automatic Detection and Classification of Tick...</td>\n",
              "      <td>Around the globe, ticks are the culprit of t...</td>\n",
              "      <td>Around the globe, ticks are the culprit of t...</td>\n",
              "      <td>[-0.032522194, -0.050377354, 0.02166548, -0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mixing Real and Synthetic Data to Enhance Neur...</td>\n",
              "      <td>Deep neural networks have gained tremendous ...</td>\n",
              "      <td>Deep neural networks have gained tremendous ...</td>\n",
              "      <td>[0.029221388, -0.06772673, 0.00891163, -0.0010...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0504f45-f640-4049-8da8-4da304561afc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0504f45-f640-4049-8da8-4da304561afc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0504f45-f640-4049-8da8-4da304561afc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-623417ee-a215-4158-9043-d21c878901f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-623417ee-a215-4158-9043-d21c878901f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-623417ee-a215-4158-9043-d21c878901f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Epsilon Consistent Mixup: Structural Regulariz...   \n",
              "1  Particle Graph Autoencoders and Differentiable...   \n",
              "2                           Probabilistic DAG Search   \n",
              "3  Automatic Detection and Classification of Tick...   \n",
              "4  Mixing Real and Synthetic Data to Enhance Neur...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0    In this paper we propose $\\epsilon$-Consiste...   \n",
              "1    Autoencoders have useful applications in hig...   \n",
              "2    Exciting contemporary machine learning probl...   \n",
              "3    Around the globe, ticks are the culprit of t...   \n",
              "4    Deep neural networks have gained tremendous ...   \n",
              "\n",
              "                                                text  \\\n",
              "0    In this paper we propose $\\epsilon$-Consiste...   \n",
              "1    Autoencoders have useful applications in hig...   \n",
              "2    Exciting contemporary machine learning probl...   \n",
              "3    Around the globe, ticks are the culprit of t...   \n",
              "4    Deep neural networks have gained tremendous ...   \n",
              "\n",
              "                                          embeddings  \n",
              "0  [0.004646845, -0.012128952, -0.019156834, -0.0...  \n",
              "1  [-0.036488354, 0.013384212, 0.007417859, 0.009...  \n",
              "2  [0.021119291, -0.03755111, -0.026112985, -0.02...  \n",
              "3  [-0.032522194, -0.050377354, 0.02166548, -0.00...  \n",
              "4  [0.029221388, -0.06772673, 0.00891163, -0.0010...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert HF dataset to Pandas DF\n",
        "df = embeddings_ds.to_pandas()\n",
        "\n",
        "# Take a peek at the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhLlCpQODaT3"
      },
      "source": [
        "## Insert the embeddings into Weaviate\n",
        "### Create and configure an embedded Weaviate collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho7xYQTZK5Wk"
      },
      "source": [
        "[Embedded Weaviate](https://weaviate.io/developers/weaviate/installation/embedded) allows you to spin up a Weaviate instance directly from your application code, without having to use a Docker container.\n",
        "\n",
        "If you're interested in other deployment methods, like using Docker-Compose or Kubernetes, check out this [page](https://weaviate.io/developers/weaviate/installation) in the Weaviate docs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFUBEZiJUMic",
        "outputId": "360e30e0-f10b-48f8-e2df-109a77b3cad7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 21500\n"
          ]
        }
      ],
      "source": [
        "import weaviate\n",
        "\n",
        "# Connect to Weaviate\n",
        "client = weaviate.connect_to_embedded()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqqyQSFt1TWr"
      },
      "source": [
        "Next, we define the collection and its properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9jEhxseguKf9"
      },
      "outputs": [],
      "source": [
        "import weaviate.classes as wvc\n",
        "import weaviate.classes.config as wc\n",
        "from weaviate.classes.config import Property, DataType\n",
        "\n",
        "# Define the collection name\n",
        "collection_name = \"ml_papers\"\n",
        "\n",
        "# Delete the collection if it already exists\n",
        "if (client.collections.exists(collection_name)):\n",
        "    client.collections.delete(collection_name)\n",
        "\n",
        "# Create the collection\n",
        "collection = client.collections.create(\n",
        "    collection_name,\n",
        "    vectorizer_config = wvc.config.Configure.Vectorizer.none(),\n",
        "\n",
        "    # Define properties of metadata\n",
        "    properties=[\n",
        "        wc.Property(\n",
        "            name=\"text\",\n",
        "            data_type=wc.DataType.TEXT\n",
        "        ),\n",
        "        wc.Property(\n",
        "            name=\"title\",\n",
        "            data_type=wc.DataType.TEXT,\n",
        "            skip_vectorization=True\n",
        "        ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FKKoIx01awT"
      },
      "source": [
        "Finally, we insert the embeddings and metadata into our Weaviate collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HhxnBF8h1fLu"
      },
      "outputs": [],
      "source": [
        "# Insert embeddings and metadata into collection\n",
        "objs = []\n",
        "for i, d in enumerate(df[\"text\"]):\n",
        "    objs.append(wvc.data.DataObject(\n",
        "            properties={\n",
        "                \"text\": df[\"text\"][i],\n",
        "                \"title\": df[\"title\"][i],\n",
        "            },\n",
        "            vector = df[\"embeddings\"][i].tolist()\n",
        "        )\n",
        "    )\n",
        "\n",
        "collection.data.insert_many(objs);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI01PxjuD_XR"
      },
      "source": [
        "## Query the data using similarity search\n",
        "\n",
        "Here, we perform a simple similarity search to return the most similar embedded chunks to our search query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qI3w-Lkdv8Vt"
      },
      "outputs": [],
      "source": [
        "# Define query and number of results\n",
        "query = \"Which papers apply ML to the medical domain?\"\n",
        "\n",
        "top_n = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbz6nWJc5CSj",
        "outputId": "9527cb40-2d83-4d7f-c7aa-c3f92c374f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 3 results:\n",
            "\n",
            "Locally orderless tensor networks for classifying two- and\n",
            "  three-dimensional medical images\n",
            "\n",
            "\n",
            "Applications of Generative Adversarial Networks in Neuroimaging and Clinical Neuroscience\n",
            "\n",
            "\n",
            "Scaling Datalog for Machine Learning on Big Data\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from weaviate.classes.query import MetadataQuery\n",
        "\n",
        "query_embedding = model.encode(\n",
        "    query,\n",
        "    convert_to_tensor=True\n",
        ")\n",
        "\n",
        "results = collection.query.near_vector(\n",
        "    near_vector = query_embedding.tolist(),\n",
        "    limit=top_n\n",
        ")\n",
        "\n",
        "print(f\"Top {top_n} results:\\n\")\n",
        "for i, obj in enumerate(results.objects):\n",
        "    print(obj.properties['title'])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tGz49nfUegG"
      },
      "source": [
        "‚òÅÔ∏è Want to scale this notebook? \n",
        "\n",
        "üòç Get 14 days of free access to Weaviate Cloud's Sandbox by creating an account [here](https://auth.wcs.api.weaviate.io/auth/realms/SeMI/login-actions/registration?client_id=wcs-frontend&tab_id=zRaiBYjkzc4). \n",
        "\n",
        "*No name, no credit card required.*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
