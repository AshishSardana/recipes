{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patronus `Lynx` Hallucination Detection\n",
    "\n",
    "This notebook will illustrates how to use `Lynx` from Patronus, a custom model for hallucination evaluation with the Weaviate Query Agent.\n",
    "\n",
    "> This notebook is using patronus `0.1.3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Patronus Setup Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/41/8dp_379x15d8zz4ppsjthdw40000gn/T/ipykernel_86934/129833330.py:4: UserWarning: The Patronus SDK has already been initialized. Duplicate initialization attempts are ignored.\n",
      "  patronus.init(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=0.01 pass_=False text_output=None metadata={'positions': [[0, 19]], 'extra': None, 'confidence_interval': None} explanation='\\'The context mentions that the blue whale is the largest known animal on the planet.\\', \\'The context also mentions that in the book Dune, Sandworms are the largest animals, but this is in a fictional context.\\', \"The answer \\'The giant sandworm\\' is not faithful to the context because it incorrectly identifies a fictional entity as the largest animal in the world, whereas the context clearly states that the blue whale is the largest known animal.\"' tags={} dataset_id=None dataset_sample_id=None evaluation_duration=datetime.timedelta(microseconds=986000) explanation_duration=datetime.timedelta(0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import patronus\n",
    "from patronus.evals import RemoteEvaluator\n",
    "\n",
    "patronus.init(\n",
    "    os.getenv(\"PATRONUS_API_KEY\")\n",
    ")\n",
    "\n",
    "patronus_evaluator = RemoteEvaluator(\"lynx\", \"patronus:hallucination\")\n",
    "# See other built-in evaluators here - https://docs.patronus.ai/docs/evaluation_api/reference_guide\n",
    "\n",
    "result = patronus_evaluator.evaluate(\n",
    "    task_input=\"What is the largest animal in the world?\",\n",
    "    task_context=[\"The blue whale is the largest known animal on the planet.\",\"In Dune by Frank Herbert, Sandworms are the largest animals - beware if you like spice!\"],\n",
    "    task_output=\"The giant sandworm.\",\n",
    "    gold_answer=\"\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Weaviate Blogs to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import weaviate\n",
    "\n",
    "weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=os.getenv(\"WEAVIATE_URL\"),\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WEAVIATE_API_KEY\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/collections/classes/config.py:1950: PydanticDeprecatedSince211: Accessing this attribute on the instance is deprecated, and will be removed in Pydantic V3. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  for cls_field in self.model_fields:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 1463 blog chunks into Weaviate.\n",
      "Upload time: 9.30 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import time\n",
    "\n",
    "import weaviate\n",
    "import weaviate.collections.classes.config as wvcc\n",
    "from dotenv import load_dotenv\n",
    "from weaviate.classes.init import AdditionalConfig, Timeout\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "local_blogs = []\n",
    "\n",
    "main_folder_path = \"./blog/\"\n",
    "\n",
    "for i, folder_name in enumerate(os.listdir(main_folder_path)):\n",
    "    subfolder_path = os.path.join(main_folder_path, folder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        index_file_path = os.path.join(subfolder_path, \"index.mdx\")\n",
    "        if os.path.isfile(index_file_path):\n",
    "            with open(index_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "                local_blogs.append(\n",
    "                    {\n",
    "                        \"content\": content,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "if weaviate_client.collections.exists(\"Blogs\"):\n",
    "    weaviate_client.collections.delete(\"Blogs\")\n",
    "blogs = weaviate_client.collections.create(\n",
    "    name=\"Blogs\",\n",
    "    vectorizer_config=wvcc.Configure.Vectorizer.text2vec_weaviate(),\n",
    "    properties=[\n",
    "        wvcc.Property(name=\"content\", data_type=wvcc.DataType.TEXT),\n",
    "    ],\n",
    ")\n",
    "\n",
    "def chunk_text(text, max_tokens=300):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = enc.encode(text)\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk_tokens = tokens[i:i + max_tokens]\n",
    "        chunk_text = enc.decode(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "chunked_blogs = []\n",
    "for blog in local_blogs:\n",
    "    chunks = chunk_text(blog[\"content\"])\n",
    "    for chunk in chunks:\n",
    "        chunked_blogs.append({\n",
    "            \"content\": chunk\n",
    "        })\n",
    "\n",
    "start_time = time.time()\n",
    "with weaviate_client.batch.dynamic() as batch:\n",
    "    for blog_chunk in chunked_blogs:\n",
    "        batch.add_object(\n",
    "            collection=\"Blogs\",\n",
    "            properties={\n",
    "                \"content\": blog_chunk[\"content\"],\n",
    "            }\n",
    "        )\n",
    "end_time = time.time()\n",
    "upload_time = end_time - start_time\n",
    "\n",
    "print(f\"Successfully imported {len(chunked_blogs)} blog chunks into Weaviate.\")\n",
    "print(f\"Upload time: {upload_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weaviate Query Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────── 🔍 Original Query ───────────────────────────────────────────────╮\n",
       "│                                                                                                                 │\n",
       "│ How does HNSW work?                                                                                             │\n",
       "│                                                                                                                 │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────── 🔍 Original Query ───────────────────────────────────────────────╮\n",
       "│                                                                                                                 │\n",
       "│ How does HNSW work?                                                                                             │\n",
       "│                                                                                                                 │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭────────────────────────────────────────────────</span> 📝 Final Answer <span style=\"color: #008080; text-decoration-color: #008080\">────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ HNSW (Hierarchical Navigable Small World) is a graph-based algorithm used for approximate nearest neighbor      │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ search, which is highly effective for vector search operations. The core idea behind HNSW is to organize data   │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ points into a hierarchical, multi-layered graph structure. This structure allows for speedy navigation and      │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ searching within a dataset by balancing longer distances for fast navigation in the upper layers and shorter    │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ distances for precise local searching in the lower layers.                                                      │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ In an HNSW graph, the top layers are sparse and contain only long-range connections, which enable rapid         │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ traversal across the dataset. As a search query moves down through the hierarchy, the graph becomes denser,     │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ allowing for finer-grained searches until the closest data points are found in the bottom layers.               │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ HNSW is beneficial for large-scale vector search databases, like Weaviate, where it supports fast, reliable     │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ queries with high recall rates (&gt;95%) while maintaining low latency. The algorithm's hierarchical structure is  │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ key to its performance, as it allows decomposition of the search space, leading to efficient data traversal and │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ retrieval.                                                                                                      │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ Additionally, HNSW can be enhanced with features such as real-time indexing, updates, and deletions through     │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ CRUD operations, which is particularly useful for dynamic datasets that require frequent updates.               │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────────\u001b[0m 📝 Final Answer \u001b[36m───────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m                                                                                                                 \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mHNSW (Hierarchical Navigable Small World) is a graph-based algorithm used for approximate nearest neighbor \u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36msearch, which is highly effective for vector search operations. The core idea behind HNSW is to organize data \u001b[0m\u001b[36m \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mpoints into a hierarchical, multi-layered graph structure. This structure allows for speedy navigation and \u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36msearching within a dataset by balancing longer distances for fast navigation in the upper layers and shorter \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mdistances for precise local searching in the lower layers.\u001b[0m\u001b[36m                                                     \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36m                                                                                                               \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mIn an HNSW graph, the top layers are sparse and contain only long-range connections, which enable rapid \u001b[0m\u001b[36m       \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mtraversal across the dataset. As a search query moves down through the hierarchy, the graph becomes denser, \u001b[0m\u001b[36m   \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mallowing for finer-grained searches until the closest data points are found in the bottom layers.\u001b[0m\u001b[36m              \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36m                                                                                                               \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mHNSW is beneficial for large-scale vector search databases, like Weaviate, where it supports fast, reliable \u001b[0m\u001b[36m   \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mqueries with high recall rates (>95%) while maintaining low latency. The algorithm's hierarchical structure is \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mkey to its performance, as it allows decomposition of the search space, leading to efficient data traversal and\u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mretrieval.\u001b[0m\u001b[36m                                                                                                     \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36m                                                                                                               \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mAdditionally, HNSW can be enhanced with features such as real-time indexing, updates, and deletions through \u001b[0m\u001b[36m   \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[36mCRUD operations, which is particularly useful for dynamic datasets that require frequent updates.\u001b[0m\u001b[36m              \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m                                                                                                                 \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────</span> 🔭 Searches Executed 1/1 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│ </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QueryResultWithCollection</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                                                                      │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│     </span><span style=\"color: #808000; text-decoration-color: #808000\">queries</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">=</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'HNSW working mechanism'</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">]</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">,                                                                         │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│     </span><span style=\"color: #808000; text-decoration-color: #808000\">filters</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">=</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">[[]]</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">,                                                                                               │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│     </span><span style=\"color: #808000; text-decoration-color: #808000\">filter_operators</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'AND'</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">,                                                                                     │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│     </span><span style=\"color: #808000; text-decoration-color: #808000\">collection</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Blogs'</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                                                                          │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">)</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                                                                                               │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m──────────────────────────────────────────\u001b[0m 🔭 Searches Executed 1/1 \u001b[37m───────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m                                                                                                                 \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[1;35mQueryResultWithCollection\u001b[0m\u001b[1;37m(\u001b[0m\u001b[37m                                                                                     \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[37m    \u001b[0m\u001b[33mqueries\u001b[0m\u001b[37m=\u001b[0m\u001b[1;37m[\u001b[0m\u001b[32m'HNSW working mechanism'\u001b[0m\u001b[1;37m]\u001b[0m\u001b[37m,\u001b[0m\u001b[37m                                                                        \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[37m    \u001b[0m\u001b[33mfilters\u001b[0m\u001b[37m=\u001b[0m\u001b[1;37m[\u001b[0m\u001b[1;37m[\u001b[0m\u001b[1;37m]\u001b[0m\u001b[1;37m]\u001b[0m\u001b[37m,\u001b[0m\u001b[37m                                                                                              \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[37m    \u001b[0m\u001b[33mfilter_operators\u001b[0m\u001b[37m=\u001b[0m\u001b[32m'AND'\u001b[0m\u001b[37m,\u001b[0m\u001b[37m                                                                                    \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[37m    \u001b[0m\u001b[33mcollection\u001b[0m\u001b[37m=\u001b[0m\u001b[32m'Blogs'\u001b[0m\u001b[37m                                                                                         \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[1;37m)\u001b[0m\u001b[37m                                                                                                              \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m                                                                                                                 \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d75f5f; text-decoration-color: #d75f5f\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d75f5f; text-decoration-color: #d75f5f\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #d75f5f; text-decoration-color: #d75f5f\">│ 📊 No Aggregations Run                                                                                          │</span>\n",
       "<span style=\"color: #d75f5f; text-decoration-color: #d75f5f\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #d75f5f; text-decoration-color: #d75f5f\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;167m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[38;5;167m│\u001b[0m\u001b[38;5;167m                                                                                                                 \u001b[0m\u001b[38;5;167m│\u001b[0m\n",
       "\u001b[38;5;167m│\u001b[0m\u001b[38;5;167m \u001b[0m\u001b[38;5;167m📊 No Aggregations Run\u001b[0m\u001b[38;5;167m                                                                                         \u001b[0m\u001b[38;5;167m \u001b[0m\u001b[38;5;167m│\u001b[0m\n",
       "\u001b[38;5;167m│\u001b[0m\u001b[38;5;167m                                                                                                                 \u001b[0m\u001b[38;5;167m│\u001b[0m\n",
       "\u001b[38;5;167m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭──────────────────────────────────────────────────</span> 📚 Sources <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">───────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│  - object_id='6d45f1f2-136f-4ada-9725-d463b72132de' collection='Blogs'                                          │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│  - object_id='bf57ffc0-e6fb-41ed-a724-4499306bd4e4' collection='Blogs'                                          │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│  - object_id='2727f48e-986a-4635-b967-6a4733b0da97' collection='Blogs'                                          │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│                                                                                                                 │</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m─────────────────────────────────────────────────\u001b[0m 📚 Sources \u001b[37m──────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m                                                                                                                 \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='6d45f1f2-136f-4ada-9725-d463b72132de' collection='Blogs'\u001b[0m\u001b[37m                                         \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='bf57ffc0-e6fb-41ed-a724-4499306bd4e4' collection='Blogs'\u001b[0m\u001b[37m                                         \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='2727f48e-986a-4635-b967-6a4733b0da97' collection='Blogs'\u001b[0m\u001b[37m                                         \u001b[0m\u001b[37m \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m\u001b[37m                                                                                                                 \u001b[0m\u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">   📊 Usage Statistics   </span>\n",
       "┌────────────────┬──────┐\n",
       "│ LLM Requests:  │ 3    │\n",
       "│ Input Tokens:  │ 8858 │\n",
       "│ Output Tokens: │ 361  │\n",
       "│ Total Tokens:  │ 9219 │\n",
       "└────────────────┴──────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m   📊 Usage Statistics   \u001b[0m\n",
       "┌────────────────┬──────┐\n",
       "│ LLM Requests:  │ 3    │\n",
       "│ Input Tokens:  │ 8858 │\n",
       "│ Output Tokens: │ 361  │\n",
       "│ Total Tokens:  │ 9219 │\n",
       "└────────────────┴──────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Total Time Taken:</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.</span><span style=\"color: #008080; text-decoration-color: #008080\">06s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mTotal Time Taken:\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m11.\u001b[0m\u001b[36m06s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from weaviate.agents.query import QueryAgent\n",
    "from weaviate.agents.utils import print_query_agent_response\n",
    "\n",
    "qa = QueryAgent(\n",
    "    client=weaviate_client, collections=[\"Blogs\"]\n",
    ")\n",
    "\n",
    "response = qa.run(\"How does HNSW work?\")\n",
    "print_query_agent_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sources` from the Query Agent\n",
    "\n",
    "The response from the Weaviate Query Agent contains a `sources` field that can be used to help users understand what influenced the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Source(object_id='6d45f1f2-136f-4ada-9725-d463b72132de', collection='Blogs'),\n",
       " Source(object_id='bf57ffc0-e6fb-41ed-a724-4499306bd4e4', collection='Blogs'),\n",
       " Source(object_id='2727f48e-986a-4635-b967-6a4733b0da97', collection='Blogs')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Result #1\n",
      "\n",
      " pride ourselves on our research acumen and on providing state-of-the-art solutions. So we took time to explore these solutions to identify and evaluate the right building blocks for Weaviate's future.  Here we share some of our findings from this research.\n",
      "\n",
      "## On the HNSW vs. Vamana comparison\n",
      "As the first step to disk-based vector indexing, we decided to explore Vamana – the algorithm behind the DiskANN solution. Here are some key differences between Vamana and HNSW:\n",
      "\n",
      "### Vamana indexing - in short:\n",
      "* Build a random graph.\n",
      "* Optimize the graph, so it only connects vectors close to each other.\n",
      "* Modify the graph by removing some short connections and adding some long-range edges to speed up the traversal of the graph.\n",
      "\n",
      "### HNSW indexing - in short:\n",
      "* Build a hierarchy of layers to speed up the traversal of the nearest neighbor graph.\n",
      "* In this graph, the top layers contain only long-range edges.\n",
      "* The deeper the search traverses through the hierarchy, the shorter the distance between vectors captured in the edges.\n",
      "\n",
      "Put simply, Vamana can build a flat graph, in contrast to HNSW, which uses a hierarchical representation. And a flat graph may suffer less performance degradation from being stored on disk than a hierarchical representation might. The reason is that since the outgoing connections from each node are known, it is possible to store the information in such a way that we can calculate the exact position on the\n",
      "\n",
      "Search Result #2\n",
      "\n",
      "first step**, you can see that the entry point for the search is in the center, and then the long-range connections allow jumping to the edges. This means that when a query comes, it will quickly move in the appropriate direction.<br/>\n",
      "The **second**, **third**, and **final steps** highlight the nodes reachable within **three**, **six**, and **nine** hops from the entry node.\n",
      "\n",
      "HNSW, on the other hand, implements the same idea a bit differently. Instead of having all information together on a flat graph, it has a hierarchical representation distributed across multiple layers. The top layers only contain long-range connections, and as you dive deeper into the layers, your query is routed to the appropriate region where you can look more locally for your answer. So your search starts making only big jumps across the top layers until it finally looks for the closest points locally in the bottom layers.\n",
      "\n",
      "## Performance comparison\n",
      "So, how do they perform? Let's take a look in terms of speed as well as recall.\n",
      "\n",
      "The chart below illustrates a comparison of the C++ Vamana [reference code](https://github.com/microsoft/DiskANN) provided by Microsoft and our [HNSW implementation](https://github.com/weaviate/weaviate/tree/master/adapters/repos/db/vector/hnsw) when using Sift1M. Following Microsoft’s experiments, we have used sift-query.fvecs (100,000 vectors sample) for building the index and sift-query.f\n",
      "\n",
      "Search Result #3\n",
      "\n",
      "NSW works by organizing vectors into a hierarchical, multi-layered graph structure, which allows for fast navigation through the dataset during search. The structure of HNSW balances longer distances for faster search in upper layers and shorter distances for accurate search in lower layers.\n",
      "\n",
      "In Weaviate's implementation, HNSW is enhanced to support full [CRUD operations](https://weaviate.io/blog/crud-support-in-weaviate) and allows for real-time querying, updates, and deletions, with features like incremental disk writes for crash recovery and [asynchronous cleanup processes](https://github.com/nmslib/hnswlib/issues/4#issuecomment-678315156) for maintaining index freshness.\n",
      "\n",
      "Check out [Weaviate ANN benchmarks](https://weaviate.io/developers/weaviate/benchmarks/ann) to see how HNSW performed on realistic large-scale datasets. You can use it to compare the tradeoffs between recall, QPS, latency, and import time.\n",
      "\n",
      "You will find it interesting to see that Weaviate can maintain very high recall rates (\\>95%), whilst keeping high throughput and low latency (both in milliseconds). That is exactly what you need for fast, but reliable vector search\\!\n",
      "\n",
      "If you’re interested in benchmarking for your own dataset, [check out this webinar](https://events.weaviate.io/benchmarking-webinar).\n",
      "\n",
      "### ANN vs. KNN\n",
      "\n",
      "kNN, or [k-nearest neighbors (k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from weaviate.classes.query import Filter\n",
    "\n",
    "blogs_collection = weaviate_client.collections.get(\"Blogs\")\n",
    "\n",
    "source_uuids = [source.object_id for source in response.sources]\n",
    "source_uuids\n",
    "\n",
    "objects = blogs_collection.query.fetch_objects_by_ids(\n",
    "    source_uuids\n",
    ")\n",
    "\n",
    "# Format the search results in a clean, numbered format\n",
    "search_results = []\n",
    "for i, o in enumerate(objects.objects, 1):\n",
    "    content = o.properties.get('content', '')\n",
    "    search_results.append(f\"Search Result #{i}\\n\\n{content}\\n\")\n",
    "\n",
    "# Join all results into a single string and print\n",
    "formatted_results = \"\\n\".join(search_results)\n",
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Query Agent Hallucination with Patronus `Lynx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=1.0 pass_=True text_output=None metadata={'positions': [[1095, 1159], [1344, 1351], [1224, 1231], [511, 576], [245, 509], [879, 901], [1047, 1093], [1233, 1270], [864, 877], [679, 703], [115, 243], [578, 677], [1161, 1222], [705, 862]], 'extra': None, 'confidence_interval': None} explanation='- The QUESTION asks about how HNSW works.\\n- The CONTEXT provides detailed information about HNSW, including its structure and functionality.\\n- The ANSWER summarizes the key points from the CONTEXT, explaining that HNSW is a graph-based algorithm for approximate nearest neighbor search.\\n- The ANSWER mentions that HNSW organizes data points into a hierarchical, multi-layered graph structure, which allows for speedy navigation and searching.\\n- The ANSWER also notes that the top layers contain only long-range connections for fast traversal, while the lower layers provide finer-grained searches for precise results.\\n- The ANSWER highlights the benefits of HNSW, such as high recall rates and low latency, making it suitable for large-scale vector search databases like Weaviate.\\n- The ANSWER also mentions the support for CRUD operations, which is useful for dynamic datasets.\\n- The ANSWER is faithful to the CONTEXT as it accurately reflects the information provided about HNSW, including its structure, functionality, and benefits.' tags={} dataset_id=None dataset_sample_id=None evaluation_duration=datetime.timedelta(seconds=2, microseconds=920000) explanation_duration=datetime.timedelta(0)\n"
     ]
    }
   ],
   "source": [
    "result = patronus_evaluator.evaluate(\n",
    "    task_input=\"How does HNSW work?\",\n",
    "    task_context=[formatted_results],\n",
    "    task_output=response.final_answer,\n",
    "    gold_answer=\"\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "True\n",
      "- The QUESTION asks about how HNSW works.\n",
      "- The CONTEXT provides detailed information about HNSW, including its structure and functionality.\n",
      "- The ANSWER summarizes the key points from the CONTEXT, explaining that HNSW is a graph-based algorithm for approximate nearest neighbor search.\n",
      "- The ANSWER mentions that HNSW organizes data points into a hierarchical, multi-layered graph structure, which allows for speedy navigation and searching.\n",
      "- The ANSWER also notes that the top layers contain only long-range connections for fast traversal, while the lower layers provide finer-grained searches for precise results.\n",
      "- The ANSWER highlights the benefits of HNSW, such as high recall rates and low latency, making it suitable for large-scale vector search databases like Weaviate.\n",
      "- The ANSWER also mentions the support for CRUD operations, which is useful for dynamic datasets.\n",
      "- The ANSWER is faithful to the CONTEXT as it accurately reflects the information provided about HNSW, including its structure, functionality, and benefits.\n"
     ]
    }
   ],
   "source": [
    "print(result.score)\n",
    "print(result.pass_)\n",
    "print(result.explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
