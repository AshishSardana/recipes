{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the quick notebook on using Llama 2 ðŸ¦™ ðŸš¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To begin, make sure you:\n",
    "1. pip install weaviate-client\n",
    "2. pip install llama-index\n",
    "3. pip install replicate \n",
    "\n",
    "### You will also need to have an access key for:\n",
    "1. [OpenAI](https://openai.com/)\n",
    "2. [Replicate](https://replicate.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate \n",
    "\n",
    "client = weaviate.Client(\n",
    "  url=\"https://URL.weaviate.network\",  # URL to Weaviate instance\n",
    ")\n",
    "\n",
    "client.schema.get()  # Get the schema to test connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema was created.\n"
     ]
    }
   ],
   "source": [
    "blog_post_schema = {\n",
    "   \"classes\": [\n",
    "       {\n",
    "           \"class\": \"BlogPost\",\n",
    "           \"description\": \"Blog post from the Weaviate website.\",\n",
    "           \"vectorizer\": \"text2vec-openai\",\n",
    "           \"properties\": [\n",
    "               {\n",
    "                  \"name\": \"Content\",\n",
    "                  \"dataType\": [\"text\"],\n",
    "                  \"description\": \"Content from the blog post\",\n",
    "               }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "client.schema.delete_all()\n",
    "\n",
    "client.schema.create(blog_post_schema)\n",
    "\n",
    "print(\"Schema was created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# load the blogs in using the reader\n",
    "blogs = SimpleDirectoryReader('./data').load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index import VectorStoreIndex, ListIndex\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "vector_store = WeaviateVectorStore(weaviate_client=client, class_prefix=\"Blogs_index\")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(blogs, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import Replicate\n",
    "from llama_index import ServiceContext, set_global_service_context\n",
    "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\n",
    "\n",
    "# The replicate endpoint\n",
    "LLAMA_13B_V2_CHAT = \"a16z-infra/llama13b-v2-chat:5ec5fdadd80ace49f5a2b2178cceeb9f2f77c493b85b1131002c26e6b2b13184\"\n",
    "\n",
    "# inject custom system prompt into llama-2\n",
    "def custom_completion_to_prompt(completion: str) -> str:\n",
    "    return completion_to_prompt(\n",
    "        completion,\n",
    "        system_prompt=(\n",
    "            \"You are a Q&A assistant. Your goal is to answer questions as \"\n",
    "            \"accurately as possible in the instructions and context provided.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "llm = Replicate(\n",
    "    model=LLAMA_13B_V2_CHAT,\n",
    "    temperature=0,\n",
    "    # override max tokens since it's interpreted\n",
    "    # as context window instead of max tokens\n",
    "    context_window=4096,\n",
    "    # override completion representation for llama 2\n",
    "    completion_to_prompt=custom_completion_to_prompt\n",
    ")\n",
    "\n",
    "# set a global service context\n",
    "ctx = ServiceContext.from_defaults(llm=llm)\n",
    "set_global_service_context(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ref2Vec is a feature in Weaviate that allows for the vectorization of data objects, including cross-references to other objects. In the context of recommendation systems, Ref2Vec can be used to represent a user's interests by drawing a graph of cross-references from the user to objects they have engaged with. This allows Weaviate to conveniently and immediately learn from each user's preferences and actions to provide improved and up-to-date characterizations.\n",
      "The benefits of using Ref2Vec in recommendation systems include:\n",
      "1. Capturing user interests and tendencies: By representing a user's interests and tendencies across multiple axes, such as product categories or even fashion styles, Ref2Vec can help improve the accuracy of recommendations.\n",
      "2. Improved relevance ranking: By using the averaged vector of a user's cross-referenced objects as a search query in Product objects, Ref2Vec can help rank search results based on relevance to the user's interests.\n",
      "3. Lightning-fast recommendations: Ref2Vec can power high-quality, lightning-fast recommendations by leveraging the ANN index of vector representations in Weaviate.\n",
      "\n",
      "In summary, Ref2Vec is a powerful feature in Weaviate that can help build recommendation systems that are more accurate, personalized, and efficient. By representing a user's interests and tendencies across multiple axes, Ref2Vec can help improve the relevance ranking of recommendations and provide a better user experience.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is ref2vec? How does this feature help with building recommendation systems?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
