{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Notebook! ü•≥\n",
    "\n",
    "In this notebook, you will learn how to optimize your DSPy program using COPRO. We will compile `Command-R` to improve the performance of `Command-R`!\n",
    "\n",
    "A few requirements:\n",
    "1. You'll need a running Weaviate instance\n",
    "    1. You can create a 14-day free cluster on [WCS](https://console.weaviate.cloud/)\n",
    "    1. Or run Weaviate locally (use the `yaml` file in this folder)\n",
    "1. Generate a Coehre API key\n",
    "1. Installations\n",
    "    1. weaviate-client\n",
    "    1. dspy-ai\n",
    "1. Load your Weaviate cluster with data\n",
    "    1. If you want to use the Weaviate blogs as the dataset, refer to the `Weaviate-Import.ipynb` file in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Disable logs with severity levelINFO and below\n",
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: GET https://hkwrfqgurmse7pygkia1gw.c0.us-east1.gcp.weaviate.cloud/v1/meta \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.weaviate_rm import WeaviateRM\n",
    "import weaviate\n",
    "\n",
    "command_r = dspy.Cohere(model=\"command-r\", max_tokens=2000, api_key=\"ai-key\")\n",
    "\n",
    "weaviate_client = weaviate.connect_to_wcs(cluster_url =\"wcs-url\", \n",
    "                                  auth_credentials=weaviate.auth.AuthApiKey(\"wcs-auth-key\"))\n",
    "retriever_model = WeaviateRM(\"WeaviateBlogChunk\", weaviate_client=weaviate_client)\n",
    "dspy.settings.configure(lm=command_r, rm=retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: phoenix_dataset_493991eb-71fa-43af-8077-16875e97c18a initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikacardenas/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# Phoenix Setup\n",
    "import phoenix as px\n",
    "phoenix_session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikacardenas/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/opentelemetry/instrumentation/dependencies.py:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import (\n"
     ]
    }
   ],
   "source": [
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "resource = Resource(attributes={})\n",
    "tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
    "span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "DSPyInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hello! How's it going? I hope you're having a fantastic day! üòä\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_r(\"say hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming 'dataset.json' is in the same directory as this script\n",
    "file_path = './WeaviateBlogRAG-0-0-0.json'\n",
    "\n",
    "# Read the dataset from 'dataset.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "# Initialize empty lists for gold_answers and queries\n",
    "gold_answers = []\n",
    "queries = []\n",
    "\n",
    "# Parse the gold_answers and queries\n",
    "for row in dataset:\n",
    "    gold_answers.append(row[\"gold_answer\"])\n",
    "    queries.append(row[\"query\"])\n",
    "    \n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(len(gold_answers)):\n",
    "    data.append(dspy.Example(gold_answer=gold_answers[i], question=queries[i]).with_inputs(\"question\"))\n",
    "\n",
    "trainset = data[:30]\n",
    "devset = data[30:35] # Small Devset\n",
    "testset = data[35:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8\n"
     ]
    }
   ],
   "source": [
    "class Evaluator(dspy.Signature):\n",
    "    \"\"\"Evaluate the quality of a system's answer to a question according to a given criterion.\"\"\"\n",
    "    \n",
    "    context = dspy.InputField(desc=\"The context for answering the question.\")\n",
    "    criterion = dspy.InputField(desc=\"The evaluation criterion.\")\n",
    "    question = dspy.InputField(desc=\"The question asked to the system.\")\n",
    "    ground_truth_answer = dspy.InputField(desc=\"An expert written Ground Truth Answer to the question.\")\n",
    "    predicted_answer = dspy.InputField(desc=\"The system's answer to the question.\")\n",
    "    rating = dspy.OutputField(desc=\"A rating between 1 and 5. IMPORTANT!! Only output the rating as an `int` and nothing else.\")\n",
    "\n",
    "class RatingParser(dspy.Signature):\n",
    "    \"\"\"Extract the FLOAT valued rating from a string.\"\"\"\n",
    "    \n",
    "    raw_rating_response = dspy.InputField(desc=\"The string that contains the rating in it.\")\n",
    "    rating = dspy.OutputField(desc=\"A FLOAT valued rating.\")\n",
    "    \n",
    "class Summarizer(dspy.Signature):\n",
    "    \"\"\"Summarize the information provided in the search results in 5 sentences.\"\"\"\n",
    "    \n",
    "    question = dspy.InputField(desc=\"a question to a search engine\")\n",
    "    context = dspy.InputField(desc=\"context filtered as relevant to the query by a search engine\")\n",
    "    summary = dspy.OutputField(desc=\"a 5 sentence summary of information in the context that would help answer the question.\")\n",
    "\n",
    "class RAGMetricProgram(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.evaluator = dspy.Predict(Evaluator)\n",
    "        self.rating_parser = dspy.Predict(RatingParser)\n",
    "        self.summarizer = dspy.Predict(Summarizer)\n",
    "    \n",
    "    def forward(self, gold, pred, trace=None):\n",
    "        # Todo add trace to interface with teleprompters\n",
    "        predicted_answer = pred.answer\n",
    "        question = gold.question\n",
    "        ground_truth_answer = gold.gold_answer\n",
    "        \n",
    "        detail = \"Is the assessed answer detailed?\"\n",
    "        faithful = \"Is the assessed answer factually supported by the context?\"\n",
    "        ground_truth = f\"The Ground Answer Truth to the Question: {question} is given as: \\n \\n {ground_truth_answer} \\n \\n How aligned is this Predicted Answer? {predicted_answer}\"\n",
    "        \n",
    "        # Judgement\n",
    "        with dspy.context(lm=command_r):\n",
    "            context = dspy.Retrieve(k=10)(question).passages\n",
    "            # Context Summary\n",
    "            context = self.summarizer(question=question, context=context).summary\n",
    "            raw_detail_response = self.evaluator(context=context, \n",
    "                                 criterion=detail,\n",
    "                                 question=question,\n",
    "                                 ground_truth_answer=ground_truth_answer,\n",
    "                                 predicted_answer=predicted_answer).rating\n",
    "            raw_faithful_response = self.evaluator(context=context, \n",
    "                                 criterion=faithful,\n",
    "                                 question=question,\n",
    "                                 ground_truth_answer=ground_truth_answer,\n",
    "                                 predicted_answer=predicted_answer).rating\n",
    "            raw_ground_truth_response = self.evaluator(context=context, \n",
    "                                 criterion=ground_truth,\n",
    "                                 question=question,\n",
    "                                 ground_truth_answer=ground_truth_answer,\n",
    "                                 predicted_answer=predicted_answer).rating\n",
    "        \n",
    "        # Structured Output Parsing\n",
    "        with dspy.context(lm=command_r):\n",
    "            detail_rating = self.rating_parser(raw_rating_response=raw_detail_response).rating\n",
    "            faithful_rating = self.rating_parser(raw_rating_response=raw_faithful_response).rating\n",
    "            ground_truth_rating = self.rating_parser(raw_rating_response=raw_ground_truth_response).rating\n",
    "        \n",
    "        total = float(detail_rating) + float(faithful_rating)*2 + float(ground_truth_rating)\n",
    "    \n",
    "        return total / 5.0\n",
    "\n",
    "toy_ground_truth_answer = \"\"\"\n",
    "Cross encoders score the relevance of a document to a query. They are commonly used to rerank documents.\n",
    "\"\"\"\n",
    "\n",
    "lgtm_query = \"What do cross encoders do?\"\n",
    "lgtm_example = dspy.Example(question=lgtm_query, gold_answer=toy_ground_truth_answer)\n",
    "\n",
    "\n",
    "# If this is your first time exploring LLM metrics,\n",
    "# I recommend trying the exercise of improving this answer to achieve a higher LLM rating.\n",
    "\n",
    "lgtm_pred = dspy.Example(answer=\"They re-rank documents.\")\n",
    "\n",
    "llm_metric = RAGMetricProgram()\n",
    "llm_metric_rating = llm_metric(lgtm_example, lgtm_pred)\n",
    "print(llm_metric_rating)\n",
    "\n",
    "def MetricWrapper(gold, pred, trace=None):\n",
    "    return llm_metric(gold, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Assess the the context and answer the question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"Helpful information for answering the question.\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"A detailed answer that is supported by the context.\")\n",
    "    \n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = dspy.Predict(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        with dspy.context(lm=command_r):\n",
    "            pred = self.generate_answer(context=context, question=question).answer\n",
    "        return dspy.Prediction(context=context, answer=pred, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGTM test query: What do cross encoders do? \n",
      " \n",
      " \n",
      "Uncompiled Answer: Cross-encoders are ranking models used for content-based re-ranking. They output a value indicating the similarity between a pair of data items, such as two sentences. They're called cross-encoders because the input consists of a pair of data items, and the model encodes them crossly. You need to use a cross-encoder with each data item and search query to calculate their similarity. They're more accurate but slower than bi-encoders. \n",
      " \n",
      "\n",
      "LLM Metric Rating: 4.0\n"
     ]
    }
   ],
   "source": [
    "uncompiled_Prediction = RAG()(lgtm_query)\n",
    "print(f\"LGTM test query: {lgtm_query} \\n \\n \")\n",
    "print(f\"Uncompiled Answer: {uncompiled_Prediction.answer} \\n \\n\")\n",
    "test_example = dspy.Example(question=lgtm_query, gold_answer=toy_ground_truth_answer)\n",
    "test_pred = uncompiled_Prediction\n",
    "llm_metric_rating = llm_metric(test_example, test_pred)\n",
    "print(f\"LLM Metric Rating: {llm_metric_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.6 / 5  (392.0%)\n"
     ]
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "evaluate = Evaluate(devset=devset, num_threads=4, display_progress=False)\n",
    "\n",
    "uncompiled_score = evaluate(RAG(), metric=MetricWrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give you a ``signature`` of fields (inputs and outputs) in English. Your task is to propose an instruction that will lead a good language model to perform the task well. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Basic Instruction: The initial instructions before optimization\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Basic Instruction: Assess the the context and answer the question.\n",
      "Proposed Instruction:\u001b[32mBasic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context. \n",
      "\n",
      "Proposed Prefix For Output Field: \"Context understood. Here's the answer:\"\u001b[0m\u001b[31m \t (and 290 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give you a ``signature`` of fields (inputs and outputs) in English. Your task is to propose an instruction that will lead a good language model to perform the task well. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Basic Instruction: The initial instructions before optimization\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Basic Instruction: Assess the the context and answer the question.\n",
      "Proposed Instruction:\u001b[32mBasic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context. \n",
      "\n",
      "Proposed Prefix For Output Field: \"Context understood. Here's the answer:\"\u001b[0m\u001b[31m \t (and 290 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Iteration Depth: 1/3.\n",
      "----------------\n",
      "Predictor 1\n",
      "i: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "p: Context understood. Here's the answer:\n",
      "\n",
      "At Depth 1/3, Evaluating Prompt Candidate #1/2 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:12<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/erikacardenas/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:266: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4.0' '4.0' '4.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_47144 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_47144 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_47144_row0_col0, #T_47144_row0_col1, #T_47144_row0_col2, #T_47144_row0_col3, #T_47144_row0_col4, #T_47144_row0_col5, #T_47144_row1_col0, #T_47144_row1_col1, #T_47144_row1_col2, #T_47144_row1_col3, #T_47144_row1_col4, #T_47144_row1_col5, #T_47144_row2_col0, #T_47144_row2_col1, #T_47144_row2_col2, #T_47144_row2_col3, #T_47144_row2_col4, #T_47144_row2_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_47144\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_47144_level0_col0\" class=\"col_heading level0 col0\" >gold_answer</th>\n",
       "      <th id=\"T_47144_level0_col1\" class=\"col_heading level0 col1\" >example_question</th>\n",
       "      <th id=\"T_47144_level0_col2\" class=\"col_heading level0 col2\" >context</th>\n",
       "      <th id=\"T_47144_level0_col3\" class=\"col_heading level0 col3\" >answer</th>\n",
       "      <th id=\"T_47144_level0_col4\" class=\"col_heading level0 col4\" >pred_question</th>\n",
       "      <th id=\"T_47144_level0_col5\" class=\"col_heading level0 col5\" >MetricWrapper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_47144_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_47144_row0_col0\" class=\"data row0 col0\" >The Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search plays a crucial role in the calculation of the Inverse Document Frequency...</td>\n",
       "      <td id=\"T_47144_row0_col1\" class=\"data row0 col1\" >What is the role of the Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search?</td>\n",
       "      <td id=\"T_47144_row0_col2\" class=\"data row0 col2\" >['Note, the current implementation of hybrid search in Weaviate uses BM25/BM25F and vector search. If you‚Äôre interested to learn about how dense vector indexes are...</td>\n",
       "      <td id=\"T_47144_row0_col3\" class=\"data row0 col3\" >The Binary Independence Model is a key component of the BM25 algorithm as it forms the basis for the normalization penalty. This penalty serves to...</td>\n",
       "      <td id=\"T_47144_row0_col4\" class=\"data row0 col4\" >What is the role of the Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search?</td>\n",
       "      <td id=\"T_47144_row0_col5\" class=\"data row0 col5\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_47144_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_47144_row1_col0\" class=\"data row1 col0\" >Vector libraries might not be suitable for applications that require real-time updates and scalable semantic search because they have immutable index data, preventing real-time updates....</td>\n",
       "      <td id=\"T_47144_row1_col1\" class=\"data row1 col1\" >Why might vector libraries not be suitable for applications that require real-time updates and scalable semantic search?</td>\n",
       "      <td id=\"T_47144_row1_col2\" class=\"data row1 col2\" >['Updatability: The index data is immutable, and thus no real-time updates are possible. 2. Scalability: Most vector libraries cannot be queried while importing your data,...</td>\n",
       "      <td id=\"T_47144_row1_col3\" class=\"data row1 col3\" >Vector libraries are not suitable for applications requiring real-time updates and scalable semantic search because the index data is immutable, which means no real-time updates...</td>\n",
       "      <td id=\"T_47144_row1_col4\" class=\"data row1 col4\" >Why might vector libraries not be suitable for applications that require real-time updates and scalable semantic search?</td>\n",
       "      <td id=\"T_47144_row1_col5\" class=\"data row1 col5\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_47144_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_47144_row2_col0\" class=\"data row2 col0\" >The document recommends the \"LangChain Guide\" by Paul from CommandBar for learning about LangChain projects.</td>\n",
       "      <td id=\"T_47144_row2_col1\" class=\"data row2 col1\" >What guide does the document recommend for learning about LangChain projects?</td>\n",
       "      <td id=\"T_47144_row2_col2\" class=\"data row2 col2\" >[\"I recommend checking out the GitHub repository to test this out yourself!\\n\\n## Additional Resources\\n‚Ä¢ [LangChain Guide](https://www.commandbar.com/blog/langchain-projects) by Paul from CommandBar. import StayConnected from '/_includes/stay-connected.mdx'\\n\\n<StayConnected />\",...</td>\n",
       "      <td id=\"T_47144_row2_col3\" class=\"data row2 col3\" >The document recommends the LangChain Guide available at https://www.commandbar.com/blog/langchain-projects for learning about LangChain projects. The guide provides an in-depth overview of LangChain and its capabilities.</td>\n",
       "      <td id=\"T_47144_row2_col4\" class=\"data row2 col4\" >What guide does the document recommend for learning about LangChain projects?</td>\n",
       "      <td id=\"T_47144_row2_col5\" class=\"data row2 col5\" >4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x169fffc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Extract the FLOAT valued rating from a string.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Rating Response: The string that contains the rating in it.\n",
      "Rating: A FLOAT valued rating.\n",
      "\n",
      "---\n",
      "\n",
      "Raw Rating Response: 5\n",
      "Rating:\u001b[32m5.0\u001b[0m\u001b[31m \t (and 2 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "prompt_model.inspect_history(n=1) \n",
      "\n",
      "\n",
      "Extract the FLOAT valued rating from a string.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Rating Response: The string that contains the rating in it.\n",
      "Rating: A FLOAT valued rating.\n",
      "\n",
      "---\n",
      "\n",
      "Raw Rating Response: 5\n",
      "Rating:\u001b[32m5.0\u001b[0m\u001b[31m \t (and 2 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "(instruction, prefix) ('Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\\n\\nProposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.', \"Context understood. Here's the answer:\")\n",
      "----------------\n",
      "Predictor 1\n",
      "i: Assess the the context and answer the question.\n",
      "p: Answer:\n",
      "\n",
      "At Depth 1/3, Evaluating Prompt Candidate #2/2 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:11<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/erikacardenas/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:266: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4.0' '4.0' '4.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_94dee th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_94dee td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_94dee_row0_col0, #T_94dee_row0_col1, #T_94dee_row0_col2, #T_94dee_row0_col3, #T_94dee_row0_col4, #T_94dee_row0_col5, #T_94dee_row1_col0, #T_94dee_row1_col1, #T_94dee_row1_col2, #T_94dee_row1_col3, #T_94dee_row1_col4, #T_94dee_row1_col5, #T_94dee_row2_col0, #T_94dee_row2_col1, #T_94dee_row2_col2, #T_94dee_row2_col3, #T_94dee_row2_col4, #T_94dee_row2_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_94dee\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_94dee_level0_col0\" class=\"col_heading level0 col0\" >gold_answer</th>\n",
       "      <th id=\"T_94dee_level0_col1\" class=\"col_heading level0 col1\" >example_question</th>\n",
       "      <th id=\"T_94dee_level0_col2\" class=\"col_heading level0 col2\" >context</th>\n",
       "      <th id=\"T_94dee_level0_col3\" class=\"col_heading level0 col3\" >answer</th>\n",
       "      <th id=\"T_94dee_level0_col4\" class=\"col_heading level0 col4\" >pred_question</th>\n",
       "      <th id=\"T_94dee_level0_col5\" class=\"col_heading level0 col5\" >MetricWrapper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_94dee_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_94dee_row0_col0\" class=\"data row0 col0\" >The Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search plays a crucial role in the calculation of the Inverse Document Frequency...</td>\n",
       "      <td id=\"T_94dee_row0_col1\" class=\"data row0 col1\" >What is the role of the Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search?</td>\n",
       "      <td id=\"T_94dee_row0_col2\" class=\"data row0 col2\" >['Note, the current implementation of hybrid search in Weaviate uses BM25/BM25F and vector search. If you‚Äôre interested to learn about how dense vector indexes are...</td>\n",
       "      <td id=\"T_94dee_row0_col3\" class=\"data row0 col3\" >The Binary Independence Model is a key component of the BM25 algorithm because it provides the basis for the normalization penalty. This penalty evaluates a...</td>\n",
       "      <td id=\"T_94dee_row0_col4\" class=\"data row0 col4\" >What is the role of the Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search?</td>\n",
       "      <td id=\"T_94dee_row0_col5\" class=\"data row0 col5\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94dee_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_94dee_row1_col0\" class=\"data row1 col0\" >Vector libraries might not be suitable for applications that require real-time updates and scalable semantic search because they have immutable index data, preventing real-time updates....</td>\n",
       "      <td id=\"T_94dee_row1_col1\" class=\"data row1 col1\" >Why might vector libraries not be suitable for applications that require real-time updates and scalable semantic search?</td>\n",
       "      <td id=\"T_94dee_row1_col2\" class=\"data row1 col2\" >['Updatability: The index data is immutable, and thus no real-time updates are possible. 2. Scalability: Most vector libraries cannot be queried while importing your data,...</td>\n",
       "      <td id=\"T_94dee_row1_col3\" class=\"data row1 col3\" >Vector libraries are not suitable for applications requiring real-time updates and scalable semantic search because the index data is immutable, which means no real-time updates...</td>\n",
       "      <td id=\"T_94dee_row1_col4\" class=\"data row1 col4\" >Why might vector libraries not be suitable for applications that require real-time updates and scalable semantic search?</td>\n",
       "      <td id=\"T_94dee_row1_col5\" class=\"data row1 col5\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94dee_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_94dee_row2_col0\" class=\"data row2 col0\" >The document recommends the \"LangChain Guide\" by Paul from CommandBar for learning about LangChain projects.</td>\n",
       "      <td id=\"T_94dee_row2_col1\" class=\"data row2 col1\" >What guide does the document recommend for learning about LangChain projects?</td>\n",
       "      <td id=\"T_94dee_row2_col2\" class=\"data row2 col2\" >[\"I recommend checking out the GitHub repository to test this out yourself!\\n\\n## Additional Resources\\n‚Ä¢ [LangChain Guide](https://www.commandbar.com/blog/langchain-projects) by Paul from CommandBar. import StayConnected from '/_includes/stay-connected.mdx'\\n\\n<StayConnected />\",...</td>\n",
       "      <td id=\"T_94dee_row2_col3\" class=\"data row2 col3\" >The document recommends the LangChain Guide by Paul from CommandBar import StayConnected for learning about LangChain projects. The guide's link is provided as: https://www.commandbar.com/blog/langchain-projects.</td>\n",
       "      <td id=\"T_94dee_row2_col4\" class=\"data row2 col4\" >What guide does the document recommend for learning about LangChain projects?</td>\n",
       "      <td id=\"T_94dee_row2_col5\" class=\"data row2 col5\" >4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x169d653d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Extract the FLOAT valued rating from a string.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Rating Response: The string that contains the rating in it.\n",
      "Rating: A FLOAT valued rating.\n",
      "\n",
      "---\n",
      "\n",
      "Raw Rating Response: 5\n",
      "Rating:\u001b[32m5.0\u001b[0m\u001b[31m \t (and 2 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "prompt_model.inspect_history(n=1) \n",
      "\n",
      "\n",
      "Extract the FLOAT valued rating from a string.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Rating Response: The string that contains the rating in it.\n",
      "Rating: A FLOAT valued rating.\n",
      "\n",
      "---\n",
      "\n",
      "Raw Rating Response: 5\n",
      "Rating:\u001b[32m5.0\u001b[0m\u001b[31m \t (and 2 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "(instruction, prefix) ('Assess the the context and answer the question.', 'Answer:')\n",
      "Updating Predictor 6074760912 to:\n",
      "i: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "p: Context understood. Here's the answer:\n",
      "Full predictor with update: \n",
      "Predictor 0\n",
      "i: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "p: Context understood. Here's the answer:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give some task instructions I've tried, along with their corresponding validation scores. The instructions are arranged in increasing order based on their scores, where higher scores indicate better quality.\n",
      "\n",
      "    Your task is to propose a new instruction that will lead a good language model to perform the task even better. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Attempted Instructions: ${attempted_instructions}\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Attempted Instructions:\n",
      "[1] ¬´Instruction #1: Assess the the context and answer the question.¬ª\n",
      "[2] ¬´Prefix #1: Answer:¬ª\n",
      "[3] ¬´Resulting Score #1: 400.0¬ª\n",
      "[4] ¬´Instruction #2: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.¬ª\n",
      "[5] ¬´Prefix #2: Context understood. Here's the answer:¬ª\n",
      "[6] ¬´Resulting Score #2: 400.0¬ª\n",
      "Proposed Instruction:\u001b[32mAttempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated. \n",
      "\n",
      "Proposed Prefix For Output Field: \n",
      "Answer: [insert concise response here],\n",
      "\n",
      "Explanation:\u001b[0m\u001b[31m \t (and 747 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give some task instructions I've tried, along with their corresponding validation scores. The instructions are arranged in increasing order based on their scores, where higher scores indicate better quality.\n",
      "\n",
      "    Your task is to propose a new instruction that will lead a good language model to perform the task even better. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Attempted Instructions: ${attempted_instructions}\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Attempted Instructions:\n",
      "[1] ¬´Instruction #1: Assess the the context and answer the question.¬ª\n",
      "[2] ¬´Prefix #1: Answer:¬ª\n",
      "[3] ¬´Resulting Score #1: 400.0¬ª\n",
      "[4] ¬´Instruction #2: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.¬ª\n",
      "[5] ¬´Prefix #2: Context understood. Here's the answer:¬ª\n",
      "[6] ¬´Resulting Score #2: 400.0¬ª\n",
      "Proposed Instruction:\u001b[32mAttempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated. \n",
      "\n",
      "Proposed Prefix For Output Field: \n",
      "Answer: [insert concise response here],\n",
      "\n",
      "Explanation:\u001b[0m\u001b[31m \t (and 747 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give some task instructions I've tried, along with their corresponding validation scores. The instructions are arranged in increasing order based on their scores, where higher scores indicate better quality.\n",
      "\n",
      "    Your task is to propose a new instruction that will lead a good language model to perform the task even better. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Attempted Instructions: ${attempted_instructions}\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Attempted Instructions:\n",
      "[1] ¬´Instruction #1: Assess the the context and answer the question.¬ª\n",
      "[2] ¬´Prefix #1: Answer:¬ª\n",
      "[3] ¬´Resulting Score #1: 400.0¬ª\n",
      "[4] ¬´Instruction #2: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.¬ª\n",
      "[5] ¬´Prefix #2: Context understood. Here's the answer:¬ª\n",
      "[6] ¬´Resulting Score #2: 400.0¬ª\n",
      "Proposed Instruction:\u001b[32mAttempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated. \n",
      "\n",
      "Proposed Prefix For Output Field: \n",
      "Answer: [insert concise response here],\n",
      "\n",
      "Explanation:\u001b[0m\u001b[31m \t (and 747 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give some task instructions I've tried, along with their corresponding validation scores. The instructions are arranged in increasing order based on their scores, where higher scores indicate better quality.\n",
      "\n",
      "    Your task is to propose a new instruction that will lead a good language model to perform the task even better. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Attempted Instructions: ${attempted_instructions}\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Attempted Instructions:\n",
      "[1] ¬´Instruction #1: Assess the the context and answer the question.¬ª\n",
      "[2] ¬´Prefix #1: Answer:¬ª\n",
      "[3] ¬´Resulting Score #1: 400.0¬ª\n",
      "[4] ¬´Instruction #2: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.¬ª\n",
      "[5] ¬´Prefix #2: Context understood. Here's the answer:¬ª\n",
      "[6] ¬´Resulting Score #2: 400.0¬ª\n",
      "Proposed Instruction:\u001b[32mAttempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated. \n",
      "\n",
      "Proposed Prefix For Output Field: \n",
      "Answer: [insert concise response here],\n",
      "\n",
      "Explanation:\u001b[0m\u001b[31m \t (and 747 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Iteration Depth: 2/3.\n",
      "----------------\n",
      "Predictor 1\n",
      "i: Attempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated.\n",
      "p: Answer: [insert concise response here],\n",
      "\n",
      "Explanation:\n",
      "\n",
      "At Depth 2/3, Evaluating Prompt Candidate #1/1 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/erikacardenas/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:266: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4.0' '4.0' '4.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0549c th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0549c td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0549c_row0_col0, #T_0549c_row0_col1, #T_0549c_row0_col2, #T_0549c_row0_col3, #T_0549c_row0_col4, #T_0549c_row0_col5, #T_0549c_row1_col0, #T_0549c_row1_col1, #T_0549c_row1_col2, #T_0549c_row1_col3, #T_0549c_row1_col4, #T_0549c_row1_col5, #T_0549c_row2_col0, #T_0549c_row2_col1, #T_0549c_row2_col2, #T_0549c_row2_col3, #T_0549c_row2_col4, #T_0549c_row2_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0549c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0549c_level0_col0\" class=\"col_heading level0 col0\" >gold_answer</th>\n",
       "      <th id=\"T_0549c_level0_col1\" class=\"col_heading level0 col1\" >example_question</th>\n",
       "      <th id=\"T_0549c_level0_col2\" class=\"col_heading level0 col2\" >context</th>\n",
       "      <th id=\"T_0549c_level0_col3\" class=\"col_heading level0 col3\" >answer</th>\n",
       "      <th id=\"T_0549c_level0_col4\" class=\"col_heading level0 col4\" >pred_question</th>\n",
       "      <th id=\"T_0549c_level0_col5\" class=\"col_heading level0 col5\" >MetricWrapper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0549c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0549c_row0_col0\" class=\"data row0 col0\" >The Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search plays a crucial role in the calculation of the Inverse Document Frequency...</td>\n",
       "      <td id=\"T_0549c_row0_col1\" class=\"data row0 col1\" >What is the role of the Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search?</td>\n",
       "      <td id=\"T_0549c_row0_col2\" class=\"data row0 col2\" >['Note, the current implementation of hybrid search in Weaviate uses BM25/BM25F and vector search. If you‚Äôre interested to learn about how dense vector indexes are...</td>\n",
       "      <td id=\"T_0549c_row0_col3\" class=\"data row0 col3\" >Answer: The Binary Independence Model is a key component of the BM25 algorithm as it forms the basis for calculating the length normalization penalty. Explanation:...</td>\n",
       "      <td id=\"T_0549c_row0_col4\" class=\"data row0 col4\" >What is the role of the Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search?</td>\n",
       "      <td id=\"T_0549c_row0_col5\" class=\"data row0 col5\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0549c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0549c_row1_col0\" class=\"data row1 col0\" >Vector libraries might not be suitable for applications that require real-time updates and scalable semantic search because they have immutable index data, preventing real-time updates....</td>\n",
       "      <td id=\"T_0549c_row1_col1\" class=\"data row1 col1\" >Why might vector libraries not be suitable for applications that require real-time updates and scalable semantic search?</td>\n",
       "      <td id=\"T_0549c_row1_col2\" class=\"data row1 col2\" >['Updatability: The index data is immutable, and thus no real-time updates are possible. 2. Scalability: Most vector libraries cannot be queried while importing your data,...</td>\n",
       "      <td id=\"T_0549c_row1_col3\" class=\"data row1 col3\" >Vector libraries are not suitable for real-time updates or scalable semantic search because the index data is immutable. This means that, although they offer efficient...</td>\n",
       "      <td id=\"T_0549c_row1_col4\" class=\"data row1 col4\" >Why might vector libraries not be suitable for applications that require real-time updates and scalable semantic search?</td>\n",
       "      <td id=\"T_0549c_row1_col5\" class=\"data row1 col5\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0549c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0549c_row2_col0\" class=\"data row2 col0\" >The document recommends the \"LangChain Guide\" by Paul from CommandBar for learning about LangChain projects.</td>\n",
       "      <td id=\"T_0549c_row2_col1\" class=\"data row2 col1\" >What guide does the document recommend for learning about LangChain projects?</td>\n",
       "      <td id=\"T_0549c_row2_col2\" class=\"data row2 col2\" >[\"I recommend checking out the GitHub repository to test this out yourself!\\n\\n## Additional Resources\\n‚Ä¢ [LangChain Guide](https://www.commandbar.com/blog/langchain-projects) by Paul from CommandBar. import StayConnected from '/_includes/stay-connected.mdx'\\n\\n<StayConnected />\",...</td>\n",
       "      <td id=\"T_0549c_row2_col3\" class=\"data row2 col3\" >Answer: LangChain Guide. Explanation: The provided context contains references to various resources and guides related to Weaviate and open-source contributions. However, the specific guide that...</td>\n",
       "      <td id=\"T_0549c_row2_col4\" class=\"data row2 col4\" >What guide does the document recommend for learning about LangChain projects?</td>\n",
       "      <td id=\"T_0549c_row2_col5\" class=\"data row2 col5\" >4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x169d42150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Extract the FLOAT valued rating from a string.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Rating Response: The string that contains the rating in it.\n",
      "Rating: A FLOAT valued rating.\n",
      "\n",
      "---\n",
      "\n",
      "Raw Rating Response: 5\n",
      "Rating:\u001b[32m5.0\u001b[0m\u001b[31m \t (and 2 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "prompt_model.inspect_history(n=1) \n",
      "\n",
      "\n",
      "Extract the FLOAT valued rating from a string.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Rating Response: The string that contains the rating in it.\n",
      "Rating: A FLOAT valued rating.\n",
      "\n",
      "---\n",
      "\n",
      "Raw Rating Response: 5\n",
      "Rating:\u001b[32m5.0\u001b[0m\u001b[31m \t (and 2 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "(instruction, prefix) ('Attempted Instructions: \\n- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\\n- Prefix #1: Answer: \\n- Resulting Score #1: 420.0\\n\\n- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\\n- Prefix #2: Explained Answer: \\n- Resulting Score #2: 406.0\\n\\nProposed Instruction: \\nProvide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated.', 'Answer: [insert concise response here],\\n\\nExplanation:')\n",
      "Updating Predictor 6074760912 to:\n",
      "i: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "p: Context understood. Here's the answer:\n",
      "Full predictor with update: \n",
      "Predictor 0\n",
      "i: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "p: Context understood. Here's the answer:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give some task instructions I've tried, along with their corresponding validation scores. The instructions are arranged in increasing order based on their scores, where higher scores indicate better quality.\n",
      "\n",
      "    Your task is to propose a new instruction that will lead a good language model to perform the task even better. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Attempted Instructions: ${attempted_instructions}\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Attempted Instructions:\n",
      "[1] ¬´Instruction #1: Attempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated.¬ª\n",
      "[2] ¬´Prefix #1: Answer: [insert concise response here],\n",
      "\n",
      "Explanation:¬ª\n",
      "[3] ¬´Resulting Score #1: 400.0¬ª\n",
      "[4] ¬´Instruction #2: Assess the the context and answer the question.¬ª\n",
      "[5] ¬´Prefix #2: Answer:¬ª\n",
      "[6] ¬´Resulting Score #2: 400.0¬ª\n",
      "[7] ¬´Instruction #3: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.¬ª\n",
      "[8] ¬´Prefix #3: Context understood. Here's the answer:¬ª\n",
      "[9] ¬´Resulting Score #3: 400.0¬ª\n",
      "Proposed Instruction:\u001b[32mAttempted Instructions: [1]\n",
      "Proposed Instruction: Provide a brief overview/summary followed by a more detailed explanation, ensuring clarity and conciseness in the summary while providing a comprehensive understanding in the explanation. This approach strikes a balance between accuracy and understanding, enhancing the chance of success.\n",
      "Proposed Prefix For Output Field: Summary: \n",
      "\n",
      "---\n",
      "\n",
      "Here's an example that might help illustrate the concept:\n",
      "\n",
      "Attempted Instructions: \n",
      "- Instruction #1: Write a one sentence summary of the book 'The Great Gatsby'. \n",
      "- Prefix #1: Summary: \n",
      "- Resulting Score #1: 450.0\n",
      "\n",
      "- Instruction #2: Provide a detailed summary of the plot of 'The Great Gatsby', focusing on the key events and characters. Explain how the setting contributes to the story.\n",
      "- Prefix #2: Detailed Summary: \n",
      "- Resulting Score #2: 430.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Present a concise summary of 'The Great Gatsby', followed by a deeper exploration of the story's elements, including characters, plot twists, and the symbolic significance of the setting, showcasing a thorough understanding.\n",
      "Prefix: In a nutshell:\u001b[0m\u001b[31m \t (and 1108 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give some task instructions I've tried, along with their corresponding validation scores. The instructions are arranged in increasing order based on their scores, where higher scores indicate better quality.\n",
      "\n",
      "    Your task is to propose a new instruction that will lead a good language model to perform the task even better. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Attempted Instructions: ${attempted_instructions}\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Attempted Instructions:\n",
      "[1] ¬´Instruction #1: Attempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated.¬ª\n",
      "[2] ¬´Prefix #1: Answer: [insert concise response here],\n",
      "\n",
      "Explanation:¬ª\n",
      "[3] ¬´Resulting Score #1: 400.0¬ª\n",
      "[4] ¬´Instruction #2: Assess the the context and answer the question.¬ª\n",
      "[5] ¬´Prefix #2: Answer:¬ª\n",
      "[6] ¬´Resulting Score #2: 400.0¬ª\n",
      "[7] ¬´Instruction #3: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.¬ª\n",
      "[8] ¬´Prefix #3: Context understood. Here's the answer:¬ª\n",
      "[9] ¬´Resulting Score #3: 400.0¬ª\n",
      "Proposed Instruction:\u001b[32mAttempted Instructions: [1]\n",
      "Proposed Instruction: Provide a brief overview/summary followed by a more detailed explanation, ensuring clarity and conciseness in the summary while providing a comprehensive understanding in the explanation. This approach strikes a balance between accuracy and understanding, enhancing the chance of success.\n",
      "Proposed Prefix For Output Field: Summary: \n",
      "\n",
      "---\n",
      "\n",
      "Here's an example that might help illustrate the concept:\n",
      "\n",
      "Attempted Instructions: \n",
      "- Instruction #1: Write a one sentence summary of the book 'The Great Gatsby'. \n",
      "- Prefix #1: Summary: \n",
      "- Resulting Score #1: 450.0\n",
      "\n",
      "- Instruction #2: Provide a detailed summary of the plot of 'The Great Gatsby', focusing on the key events and characters. Explain how the setting contributes to the story.\n",
      "- Prefix #2: Detailed Summary: \n",
      "- Resulting Score #2: 430.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Present a concise summary of 'The Great Gatsby', followed by a deeper exploration of the story's elements, including characters, plot twists, and the symbolic significance of the setting, showcasing a thorough understanding.\n",
      "Prefix: In a nutshell:\u001b[0m\u001b[31m \t (and 1108 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give some task instructions I've tried, along with their corresponding validation scores. The instructions are arranged in increasing order based on their scores, where higher scores indicate better quality.\n",
      "\n",
      "    Your task is to propose a new instruction that will lead a good language model to perform the task even better. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Attempted Instructions: ${attempted_instructions}\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Attempted Instructions:\n",
      "[1] ¬´Instruction #1: Attempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated.¬ª\n",
      "[2] ¬´Prefix #1: Answer: [insert concise response here],\n",
      "\n",
      "Explanation:¬ª\n",
      "[3] ¬´Resulting Score #1: 400.0¬ª\n",
      "[4] ¬´Instruction #2: Assess the the context and answer the question.¬ª\n",
      "[5] ¬´Prefix #2: Answer:¬ª\n",
      "[6] ¬´Resulting Score #2: 400.0¬ª\n",
      "[7] ¬´Instruction #3: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.¬ª\n",
      "[8] ¬´Prefix #3: Context understood. Here's the answer:¬ª\n",
      "[9] ¬´Resulting Score #3: 400.0¬ª\n",
      "Proposed Instruction:\u001b[32mAttempted Instructions: [1]\n",
      "Proposed Instruction: Provide a brief overview/summary followed by a more detailed explanation, ensuring clarity and conciseness in the summary while providing a comprehensive understanding in the explanation. This approach strikes a balance between accuracy and understanding, enhancing the chance of success.\n",
      "Proposed Prefix For Output Field: Summary: \n",
      "\n",
      "---\n",
      "\n",
      "Here's an example that might help illustrate the concept:\n",
      "\n",
      "Attempted Instructions: \n",
      "- Instruction #1: Write a one sentence summary of the book 'The Great Gatsby'. \n",
      "- Prefix #1: Summary: \n",
      "- Resulting Score #1: 450.0\n",
      "\n",
      "- Instruction #2: Provide a detailed summary of the plot of 'The Great Gatsby', focusing on the key events and characters. Explain how the setting contributes to the story.\n",
      "- Prefix #2: Detailed Summary: \n",
      "- Resulting Score #2: 430.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Present a concise summary of 'The Great Gatsby', followed by a deeper exploration of the story's elements, including characters, plot twists, and the symbolic significance of the setting, showcasing a thorough understanding.\n",
      "Prefix: In a nutshell:\u001b[0m\u001b[31m \t (and 1108 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You are an instruction optimizer for large language models. I will give some task instructions I've tried, along with their corresponding validation scores. The instructions are arranged in increasing order based on their scores, where higher scores indicate better quality.\n",
      "\n",
      "    Your task is to propose a new instruction that will lead a good language model to perform the task even better. Don't be afraid to be creative.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Attempted Instructions: ${attempted_instructions}\n",
      "Proposed Instruction: The improved instructions for the language model\n",
      "Proposed Prefix For Output Field: The string at the end of the prompt, which will help the model start solving the task\n",
      "\n",
      "---\n",
      "\n",
      "Attempted Instructions:\n",
      "[1] ¬´Instruction #1: Attempted Instructions: \n",
      "- Instruction #1: Answer the question based on the provided context, offering a concise and accurate response.\n",
      "- Prefix #1: Answer: \n",
      "- Resulting Score #1: 420.0\n",
      "\n",
      "- Instruction #2: Read and understand the context carefully, then provide a detailed explanation along with the answer. Ensure the language model focuses on clarity and comprehensiveness.\n",
      "- Prefix #2: Explained Answer: \n",
      "- Resulting Score #2: 406.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Provide a concise answer first, followed by a thorough explanation that considers potential nuances and alternatives. This two-part response ensures both accuracy and understanding are demonstrated.¬ª\n",
      "[2] ¬´Prefix #1: Answer: [insert concise response here],\n",
      "\n",
      "Explanation:¬ª\n",
      "[3] ¬´Resulting Score #1: 400.0¬ª\n",
      "[4] ¬´Instruction #2: Assess the the context and answer the question.¬ª\n",
      "[5] ¬´Prefix #2: Answer:¬ª\n",
      "[6] ¬´Resulting Score #2: 400.0¬ª\n",
      "[7] ¬´Instruction #3: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.¬ª\n",
      "[8] ¬´Prefix #3: Context understood. Here's the answer:¬ª\n",
      "[9] ¬´Resulting Score #3: 400.0¬ª\n",
      "Proposed Instruction:\u001b[32mAttempted Instructions: [1]\n",
      "Proposed Instruction: Provide a brief overview/summary followed by a more detailed explanation, ensuring clarity and conciseness in the summary while providing a comprehensive understanding in the explanation. This approach strikes a balance between accuracy and understanding, enhancing the chance of success.\n",
      "Proposed Prefix For Output Field: Summary: \n",
      "\n",
      "---\n",
      "\n",
      "Here's an example that might help illustrate the concept:\n",
      "\n",
      "Attempted Instructions: \n",
      "- Instruction #1: Write a one sentence summary of the book 'The Great Gatsby'. \n",
      "- Prefix #1: Summary: \n",
      "- Resulting Score #1: 450.0\n",
      "\n",
      "- Instruction #2: Provide a detailed summary of the plot of 'The Great Gatsby', focusing on the key events and characters. Explain how the setting contributes to the story.\n",
      "- Prefix #2: Detailed Summary: \n",
      "- Resulting Score #2: 430.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Present a concise summary of 'The Great Gatsby', followed by a deeper exploration of the story's elements, including characters, plot twists, and the symbolic significance of the setting, showcasing a thorough understanding.\n",
      "Prefix: In a nutshell:\u001b[0m\u001b[31m \t (and 1108 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Iteration Depth: 3/3.\n",
      "----------------\n",
      "Predictor 1\n",
      "i: Attempted Instructions: [1]\n",
      "Proposed Instruction: Provide a brief overview/summary followed by a more detailed explanation, ensuring clarity and conciseness in the summary while providing a comprehensive understanding in the explanation. This approach strikes a balance between accuracy and understanding, enhancing the chance of success.\n",
      "p: Summary: \n",
      "\n",
      "---\n",
      "\n",
      "Here's an example that might help illustrate the concept:\n",
      "\n",
      "Attempted Instructions: \n",
      "- Instruction #1: Write a one sentence summary of the book 'The Great Gatsby'. \n",
      "- Prefix #1: Summary: \n",
      "- Resulting Score #1: 450.0\n",
      "\n",
      "- Instruction #2: Provide a detailed summary of the plot of 'The Great Gatsby', focusing on the key events and characters. Explain how the setting contributes to the story.\n",
      "- Prefix #2: Detailed Summary: \n",
      "- Resulting Score #2: 430.0\n",
      "\n",
      "Proposed Instruction: \n",
      "Present a concise summary of 'The Great Gatsby', followed by a deeper exploration of the story's elements, including characters, plot twists, and the symbolic significance of the setting, showcasing a thorough understanding.\n",
      "Prefix: In a nutshell:\n",
      "\n",
      "At Depth 3/3, Evaluating Prompt Candidate #1/1 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:21<00:00,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/erikacardenas/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:266: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4.0' '4.0' '4.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f3674 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f3674 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f3674_row0_col0, #T_f3674_row0_col1, #T_f3674_row0_col2, #T_f3674_row0_col3, #T_f3674_row0_col4, #T_f3674_row0_col5, #T_f3674_row1_col0, #T_f3674_row1_col1, #T_f3674_row1_col2, #T_f3674_row1_col3, #T_f3674_row1_col4, #T_f3674_row1_col5, #T_f3674_row2_col0, #T_f3674_row2_col1, #T_f3674_row2_col2, #T_f3674_row2_col3, #T_f3674_row2_col4, #T_f3674_row2_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f3674\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f3674_level0_col0\" class=\"col_heading level0 col0\" >gold_answer</th>\n",
       "      <th id=\"T_f3674_level0_col1\" class=\"col_heading level0 col1\" >example_question</th>\n",
       "      <th id=\"T_f3674_level0_col2\" class=\"col_heading level0 col2\" >context</th>\n",
       "      <th id=\"T_f3674_level0_col3\" class=\"col_heading level0 col3\" >answer</th>\n",
       "      <th id=\"T_f3674_level0_col4\" class=\"col_heading level0 col4\" >pred_question</th>\n",
       "      <th id=\"T_f3674_level0_col5\" class=\"col_heading level0 col5\" >MetricWrapper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f3674_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f3674_row0_col0\" class=\"data row0 col0\" >The Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search plays a crucial role in the calculation of the Inverse Document Frequency...</td>\n",
       "      <td id=\"T_f3674_row0_col1\" class=\"data row0 col1\" >What is the role of the Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search?</td>\n",
       "      <td id=\"T_f3674_row0_col2\" class=\"data row0 col2\" >['Note, the current implementation of hybrid search in Weaviate uses BM25/BM25F and vector search. If you‚Äôre interested to learn about how dense vector indexes are...</td>\n",
       "      <td id=\"T_f3674_row0_col3\" class=\"data row0 col3\" >Context: The text describes the BM25 algorithm used in Weaviate's hybrid search and its importance, along with the recent addition of a new fusion algorithm....</td>\n",
       "      <td id=\"T_f3674_row0_col4\" class=\"data row0 col4\" >What is the role of the Binary Independence Model in the BM25 algorithm used by Weaviate's hybrid search?</td>\n",
       "      <td id=\"T_f3674_row0_col5\" class=\"data row0 col5\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3674_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f3674_row1_col0\" class=\"data row1 col0\" >Vector libraries might not be suitable for applications that require real-time updates and scalable semantic search because they have immutable index data, preventing real-time updates....</td>\n",
       "      <td id=\"T_f3674_row1_col1\" class=\"data row1 col1\" >Why might vector libraries not be suitable for applications that require real-time updates and scalable semantic search?</td>\n",
       "      <td id=\"T_f3674_row1_col2\" class=\"data row1 col2\" >['Updatability: The index data is immutable, and thus no real-time updates are possible. 2. Scalability: Most vector libraries cannot be queried while importing your data,...</td>\n",
       "      <td id=\"T_f3674_row1_col3\" class=\"data row1 col3\" >Summary: Vector libraries are efficient for in-memory vector searches but have limitations in real-time updating and scalability, making them unsuitable for dynamic applications. Vector databases...</td>\n",
       "      <td id=\"T_f3674_row1_col4\" class=\"data row1 col4\" >Why might vector libraries not be suitable for applications that require real-time updates and scalable semantic search?</td>\n",
       "      <td id=\"T_f3674_row1_col5\" class=\"data row1 col5\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3674_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f3674_row2_col0\" class=\"data row2 col0\" >The document recommends the \"LangChain Guide\" by Paul from CommandBar for learning about LangChain projects.</td>\n",
       "      <td id=\"T_f3674_row2_col1\" class=\"data row2 col1\" >What guide does the document recommend for learning about LangChain projects?</td>\n",
       "      <td id=\"T_f3674_row2_col2\" class=\"data row2 col2\" >[\"I recommend checking out the GitHub repository to test this out yourself!\\n\\n## Additional Resources\\n‚Ä¢ [LangChain Guide](https://www.commandbar.com/blog/langchain-projects) by Paul from CommandBar. import StayConnected from '/_includes/stay-connected.mdx'\\n\\n<StayConnected />\",...</td>\n",
       "      <td id=\"T_f3674_row2_col3\" class=\"data row2 col3\" >Context: The text provides valuable resources for making an open-source contribution to Weaviate, including guides, workshops, and a GitHub repository. Question: Which guide in the...</td>\n",
       "      <td id=\"T_f3674_row2_col4\" class=\"data row2 col4\" >What guide does the document recommend for learning about LangChain projects?</td>\n",
       "      <td id=\"T_f3674_row2_col5\" class=\"data row2 col5\" >4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x169906890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Extract the FLOAT valued rating from a string.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Rating Response: The string that contains the rating in it.\n",
      "Rating: A FLOAT valued rating.\n",
      "\n",
      "---\n",
      "\n",
      "Raw Rating Response: 5\n",
      "Rating:\u001b[32m5.0\u001b[0m\u001b[31m \t (and 2 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "prompt_model.inspect_history(n=1) \n",
      "\n",
      "\n",
      "Extract the FLOAT valued rating from a string.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Rating Response: The string that contains the rating in it.\n",
      "Rating: A FLOAT valued rating.\n",
      "\n",
      "---\n",
      "\n",
      "Raw Rating Response: 5\n",
      "Rating:\u001b[32m5.0\u001b[0m\u001b[31m \t (and 2 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "(instruction, prefix) ('Attempted Instructions: [1]\\nProposed Instruction: Provide a brief overview/summary followed by a more detailed explanation, ensuring clarity and conciseness in the summary while providing a comprehensive understanding in the explanation. This approach strikes a balance between accuracy and understanding, enhancing the chance of success.', \"Summary: \\n\\n---\\n\\nHere's an example that might help illustrate the concept:\\n\\nAttempted Instructions: \\n- Instruction #1: Write a one sentence summary of the book 'The Great Gatsby'. \\n- Prefix #1: Summary: \\n- Resulting Score #1: 450.0\\n\\n- Instruction #2: Provide a detailed summary of the plot of 'The Great Gatsby', focusing on the key events and characters. Explain how the setting contributes to the story.\\n- Prefix #2: Detailed Summary: \\n- Resulting Score #2: 430.0\\n\\nProposed Instruction: \\nPresent a concise summary of 'The Great Gatsby', followed by a deeper exploration of the story's elements, including characters, plot twists, and the symbolic significance of the setting, showcasing a thorough understanding.\\nPrefix: In a nutshell:\")\n",
      "Updating Predictor 6074760912 to:\n",
      "i: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "p: Context understood. Here's the answer:\n",
      "Full predictor with update: \n",
      "Predictor 0\n",
      "i: Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "p: Context understood. Here's the answer:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 1  (0.0):  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 1/5 [00:01<00:07,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 2  (0.0):  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                              | 2/5 [00:04<00:07,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 3  (0.0):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 3/5 [00:05<00:03,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 4  (0.0):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 4/5 [00:06<00:01,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, display_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, display_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     12\u001b[0m COPRO_compiled_RAG \u001b[38;5;241m=\u001b[39m COPRO_teleprompter\u001b[38;5;241m.\u001b[39mcompile(RAG(), trainset\u001b[38;5;241m=\u001b[39mtrainset[:\u001b[38;5;241m3\u001b[39m], eval_kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 13\u001b[0m eval_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCOPRO_compiled_RAG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_score)\n",
      "File \u001b[0;32m~/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:160\u001b[0m, in \u001b[0;36mEvaluate.__call__\u001b[0;34m(self, program, metric, devset, num_threads, display_progress, display_table, display, return_all_scores, return_outputs)\u001b[0m\n\u001b[1;32m    157\u001b[0m devset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(devset))\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_threads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_single_thread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapped_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_multi_thread(\n\u001b[1;32m    164\u001b[0m         wrapped_program,\n\u001b[1;32m    165\u001b[0m         devset,\n\u001b[1;32m    166\u001b[0m         num_threads,\n\u001b[1;32m    167\u001b[0m         display_progress,\n\u001b[1;32m    168\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:61\u001b[0m, in \u001b[0;36mEvaluate._execute_single_thread\u001b[0;34m(self, wrapped_program, devset, display_progress)\u001b[0m\n\u001b[1;32m     58\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(devset), dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m                  disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m display_progress)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, arg \u001b[38;5;129;01min\u001b[39;00m devset:\n\u001b[0;32m---> 61\u001b[0m     example_idx, example, prediction, score \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     reordered_devset\u001b[38;5;241m.\u001b[39mappend((example_idx, example, prediction, score))\n\u001b[1;32m     63\u001b[0m     ncorrect \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[0;32m~/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:150\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m    148\u001b[0m     current_error_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_count\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_error_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_errors:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError for example in dev set: \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m example_idx, example, \u001b[38;5;28mdict\u001b[39m(), \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:133\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m program(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexample\u001b[38;5;241m.\u001b[39minputs())\n\u001b[0;32m--> 133\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# FIXME: TODO: What's the right order? Maybe force name-based kwargs!\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# increment assert and suggest failures to program's attributes\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(program, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_assert_failures\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import COPRO\n",
    "\n",
    "COPRO_teleprompter = COPRO(prompt_model=command_r,\n",
    "                          metric=MetricWrapper,\n",
    "                          breadth=8,\n",
    "                          depth=3,\n",
    "                          init_temperature=0,\n",
    "                          verbose=True,\n",
    "                          track_stats=True)\n",
    "kwargs = dict(num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "COPRO_compiled_RAG = COPRO_teleprompter.compile(RAG(), trainset=trainset[:3], eval_kwargs=kwargs)\n",
    "eval_score = evaluate(COPRO_compiled_RAG, devset=devset, **kwargs)\n",
    "print(eval_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref2Vec, short for reference-to-vector, is a Weaviate 1.16 module that enables vectorization of a data object with cross-references to other objects. Essentially, it finds the average vector of cross-referenced vectors to represent the referencing object. It's a lightweight method to determine real-time preferences and actions, which is useful for recommendations and relevant results in apps.\n"
     ]
    }
   ],
   "source": [
    "print(COPRO_compiled_RAG(question=\"What is ref2vec?\").answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: Helpful information for answering the question.\n",
      "Question: ${question}\n",
      "Context understood. Here's the answer: A detailed answer that is supported by the context.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] ¬´---\n",
      "title: What is Ref2Vec and why you need it for your recommendation system\n",
      "slug: ref2vec-centroid\n",
      "authors: [connor]\n",
      "date: 2022-11-23\n",
      "tags: ['integrations', 'concepts']\n",
      "image: ./img/hero.png\n",
      "description: \"Weaviate introduces Ref2Vec, a new module that utilises Cross-References for Recommendation!\"\n",
      "---\n",
      "![Ref2vec-centroid](./img/hero.png)\n",
      "\n",
      "<!-- truncate -->\n",
      "\n",
      "Weaviate 1.16 introduced the [Ref2Vec](/developers/weaviate/modules/retriever-vectorizer-modules/ref2vec-centroid) module. In this article, we give you an overview of what Ref2Vec is and some examples in which it can add value such as recommendations or representing long objects. ## What is Ref2Vec? The name Ref2Vec is short for reference-to-vector, and it offers the ability to vectorize a data object with its cross-references to other objects. The Ref2Vec module currently holds the name ref2vec-**centroid** because it uses the average, or centroid vector, of the cross-referenced vectors to represent the **referencing** object.¬ª\n",
      "[2] ¬´As you have seen above, we think Ref2Vec can add value for use cases such as recommendations, re-ranking, overcoming the cold start problem and representing long objects. We are also excited to see what you build with Ref2Vec, and excited to build on this module with its future iterations. Speaking of which, we have another blog post coming soon on the development directions of Ref2Vec for the future. We will discuss topics such as **collaborative filtering**, **multiple centroids**, **graph neural networks**, and more on **re-ranking** with Ref2Vec. Stay tuned!\n",
      "\n",
      "\n",
      "import WhatNext from '/_includes/what-next.mdx'\n",
      "\n",
      "<WhatNext />¬ª\n",
      "[3] ¬´In other words, the User vector is being updated in real-time here to take into account their preferences and actions, which helps to produce more relevant results at speed. Another benefit of Ref2Vec is that this calculation is not compute-heavy, leading to low overhead. With Ref2Vec, you can use Weaviate to provide Recommendation with \"user-as-query\". This is a very common and powerful way to build Home Feed style features in apps. This can be done by sending queries like this to Weaviate:\n",
      "\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    Product (\n",
      "      nearObject: {\n",
      "        id: \"8abc5-4d5...\" # id for the User object with vector defined by ref2vec-centroid\n",
      "      }\n",
      "    ) {\n",
      "      product_name\n",
      "      price\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This short query encapsulates the power of Ref2Vec.¬ª\n",
      "Question: What is ref2vec?\n",
      "Context understood. Here's the answer:\u001b[32mRef2Vec, short for reference-to-vector, is a Weaviate 1.16 module that enables vectorization of a data object with cross-references to other objects. Essentially, it finds the average vector of cross-referenced vectors to represent the referencing object. It's a lightweight method to determine real-time preferences and actions, which is useful for recommendations and relevant results in apps.\u001b[0m\u001b[31m \t (and 394 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Basic Instruction: Read the question carefully, understand the context, and provide a thoughtful answer.\n",
      "\n",
      "Proposed Instruction: Answer the question while demonstrating a thorough understanding of the given context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: Helpful information for answering the question.\n",
      "Question: ${question}\n",
      "Context understood. Here's the answer: A detailed answer that is supported by the context.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] ¬´---\n",
      "title: What is Ref2Vec and why you need it for your recommendation system\n",
      "slug: ref2vec-centroid\n",
      "authors: [connor]\n",
      "date: 2022-11-23\n",
      "tags: ['integrations', 'concepts']\n",
      "image: ./img/hero.png\n",
      "description: \"Weaviate introduces Ref2Vec, a new module that utilises Cross-References for Recommendation!\"\n",
      "---\n",
      "![Ref2vec-centroid](./img/hero.png)\n",
      "\n",
      "<!-- truncate -->\n",
      "\n",
      "Weaviate 1.16 introduced the [Ref2Vec](/developers/weaviate/modules/retriever-vectorizer-modules/ref2vec-centroid) module. In this article, we give you an overview of what Ref2Vec is and some examples in which it can add value such as recommendations or representing long objects. ## What is Ref2Vec? The name Ref2Vec is short for reference-to-vector, and it offers the ability to vectorize a data object with its cross-references to other objects. The Ref2Vec module currently holds the name ref2vec-**centroid** because it uses the average, or centroid vector, of the cross-referenced vectors to represent the **referencing** object.¬ª\n",
      "[2] ¬´As you have seen above, we think Ref2Vec can add value for use cases such as recommendations, re-ranking, overcoming the cold start problem and representing long objects. We are also excited to see what you build with Ref2Vec, and excited to build on this module with its future iterations. Speaking of which, we have another blog post coming soon on the development directions of Ref2Vec for the future. We will discuss topics such as **collaborative filtering**, **multiple centroids**, **graph neural networks**, and more on **re-ranking** with Ref2Vec. Stay tuned!\n",
      "\n",
      "\n",
      "import WhatNext from '/_includes/what-next.mdx'\n",
      "\n",
      "<WhatNext />¬ª\n",
      "[3] ¬´In other words, the User vector is being updated in real-time here to take into account their preferences and actions, which helps to produce more relevant results at speed. Another benefit of Ref2Vec is that this calculation is not compute-heavy, leading to low overhead. With Ref2Vec, you can use Weaviate to provide Recommendation with \"user-as-query\". This is a very common and powerful way to build Home Feed style features in apps. This can be done by sending queries like this to Weaviate:\n",
      "\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    Product (\n",
      "      nearObject: {\n",
      "        id: \"8abc5-4d5...\" # id for the User object with vector defined by ref2vec-centroid\n",
      "      }\n",
      "    ) {\n",
      "      product_name\n",
      "      price\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This short query encapsulates the power of Ref2Vec.¬ª\n",
      "Question: What is ref2vec?\n",
      "Context understood. Here's the answer:\u001b[32mRef2Vec, short for reference-to-vector, is a Weaviate 1.16 module that enables vectorization of a data object with cross-references to other objects. Essentially, it finds the average vector of cross-referenced vectors to represent the referencing object. It's a lightweight method to determine real-time preferences and actions, which is useful for recommendations and relevant results in apps.\u001b[0m\u001b[31m \t (and 394 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(command_r.inspect_history(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservationSummarizer(dspy.Signature):\n",
    "    \"\"\"Given a series of observations I have made about my dataset, please summarize them into a brief 2-3 sentence summary which highlights only the most important details.\"\"\"\n",
    "\n",
    "    observations = dspy.InputField(desc=\"Observations I have made about my dataset\")\n",
    "    summary = dspy.OutputField(\n",
    "        desc=\"Two to Three sentence summary of only the most significant highlights of my observations\",\n",
    "    )\n",
    "\n",
    "\n",
    "class DatasetDescriptor(dspy.Signature):\n",
    "    (\n",
    "        \"\"\"Given several examples from a dataset please write observations about trends that hold for most or all of the samples. \"\"\"\n",
    "        \"\"\"Some areas you may consider in your observations: topics, content, syntax, conciceness, etc. \"\"\"\n",
    "        \"\"\"It will be useful to make an educated guess as to the nature of the task this dataset will enable. Don't be afraid to be creative\"\"\"\n",
    "    )\n",
    "\n",
    "    examples = dspy.InputField(desc=\"Sample data points from the dataset\")\n",
    "    observations = dspy.OutputField(desc=\"Somethings that holds true for most or all of the data you observed\")\n",
    "\n",
    "\n",
    "class DatasetDescriptorWithPriorObservations(dspy.Signature):\n",
    "    (\n",
    "        \"\"\"Given several examples from a dataset please write observations about trends that hold for most or all of the samples. \"\"\"\n",
    "        \"\"\"I will also provide you with a few observations I have already made.  Please add your own observations or if you feel the observations are comprehensive say 'COMPLETE' \"\"\"\n",
    "        \"\"\"Some areas you may consider in your observations: topics, content, syntax, conciceness, etc. \"\"\"\n",
    "        \"\"\"It will be useful to make an educated guess as to the nature of the task this dataset will enable. Don't be afraid to be creative\"\"\"\n",
    "    )\n",
    "\n",
    "    examples = dspy.InputField(desc=\"Sample data points from the dataset\")\n",
    "    prior_observations = dspy.InputField(desc=\"Some prior observations I made about the data\")\n",
    "    observations = dspy.OutputField(\n",
    "        desc=\"Somethings that holds true for most or all of the data you observed or COMPLETE if you have nothing to add\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_descriptor = dspy.Predict(DatasetDescriptor)\n",
    "dataset_descriptor_with_prior = dspy.Predict(DatasetDescriptorWithPriorObservations)\n",
    "observation_summarizer = dspy.Predict(ObservationSummarizer)\n",
    "\n",
    "def examples_to_strings(trainset):\n",
    "    example_strings = []\n",
    "    for example in trainset:\n",
    "        question = example.inputs[\"question\"]\n",
    "        gold_answer = example.gold_answer\n",
    "        example_string = f\"Question: {question}\\nAnswer: {gold_answer}\"\n",
    "        example_strings.append(example_string)\n",
    "    return example_strings\n",
    "\n",
    "print(\"HELLO\")\n",
    "batch_size=5\n",
    "for example in range(0, len(trainset), batch_size):\n",
    "    examples = examples_to_strings(trainset[i:i+batch_size])\n",
    "    examples = \"\".join(examples)\n",
    "    print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mWARNING: Projected Language Model (LM) Calls\u001b[0m\n",
      "\n",
      "Please be advised that based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\u001b[93m- Task Model: \u001b[94m\u001b[1m3\u001b[0m\u001b[93m examples in dev set * \u001b[94m\u001b[1m5\u001b[0m\u001b[93m trials * \u001b[94m\u001b[1m# of LM calls in your program\u001b[0m\u001b[93m = (\u001b[94m\u001b[1m15 * # of LM calls in your program\u001b[0m\u001b[93m) task model calls\u001b[0m\n",
      "\u001b[93m- Prompt Model: # data summarizer calls (max \u001b[94m\u001b[1m10\u001b[0m\u001b[93m) + \u001b[94m\u001b[1m10\u001b[0m\u001b[93m * \u001b[94m\u001b[1m1\u001b[0m\u001b[93m lm calls in program = \u001b[94m\u001b[1m20\u001b[0m\u001b[93m prompt model calls\u001b[0m\n",
      "\n",
      "\u001b[93m\u001b[1mEstimated Cost Calculation:\u001b[0m\n",
      "\n",
      "\u001b[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token) \n",
      "            + (Number of calls to prompt model * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001b[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001b[93m- Reducing the number of trials (`num_trials`), the size of the trainset, or the number of LM calls in your program.\u001b[0m\n",
      "\u001b[93m- Using a cheaper task model to optimize the prompt.\u001b[0m\n",
      "To proceed with the execution of this program, please confirm by typing \u001b[94m'y'\u001b[0m for yes or \u001b[94m'n'\u001b[0m for no.\n",
      "\n",
      "If you would like to bypass this confirmation step in future executions, set the \u001b[93m`requires_permission_to_run`\u001b[0m flag to \u001b[93m`False`.\u001b[0m\n",
      "\n",
      "\u001b[93mAwaiting your input...\u001b[0m\n",
      "\n",
      "Do you wish to continue? (y/n): y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:04<00:08,  4.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:04<00:08,  4.18s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:04<00:08,  4.13s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:03<00:07,  3.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:03<00:07,  3.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:04<00:08,  4.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:03<00:06,  3.44s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:03<00:07,  3.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                        | 1/3 [00:03<00:07,  3.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-28 21:38:15,053] A new study created in memory with name: no-name-01e73fb9-ee9b-46bc-9ff0-ac53a63d18be\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 3.6 / 1  (360.0):   0%|                                                                                   | 0/3 [00:05<?, ?it/s]\u001b[A\n",
      "Average Metric: 3.6 / 1  (360.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:05<00:11,  5.99s/it]\u001b[A\n",
      "Average Metric: 7.4 / 2  (370.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:10<00:11,  5.99s/it]\u001b[A\n",
      "Average Metric: 7.4 / 2  (370.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2/3 [00:10<00:05,  5.37s/it]\u001b[A\n",
      "Average Metric: 11.4 / 3  (380.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2/3 [00:14<00:05,  5.37s/it]\u001b[A\n",
      "Average Metric: 11.4 / 3  (380.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:14<00:00,  4.84s/it]\u001b[A\n",
      "[I 2024-03-28 21:38:29,578] Trial 0 finished with value: 380.0 and parameters: {'6090912784_predictor_instruction': 1, '6090912784_predictor_demos': 1}. Best is trial 0 with value: 380.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.4 / 3  (380.0%)\n",
      "Starting trial #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 4.0 / 1  (400.0):   0%|                                                                                   | 0/3 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 4.0 / 1  (400.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:04<00:09,  4.66s/it]\u001b[A\n",
      "Average Metric: 8.0 / 2  (400.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:08<00:09,  4.66s/it]\u001b[A\n",
      "Average Metric: 8.0 / 2  (400.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2/3 [00:08<00:04,  4.42s/it]\u001b[A\n",
      "Average Metric: 12.0 / 3  (400.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2/3 [00:12<00:04,  4.42s/it]\u001b[A\n",
      "Average Metric: 12.0 / 3  (400.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:12<00:00,  4.25s/it]\u001b[A\n",
      "[I 2024-03-28 21:38:42,348] Trial 1 finished with value: 400.0 and parameters: {'6090912784_predictor_instruction': 5, '6090912784_predictor_demos': 4}. Best is trial 1 with value: 400.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.0 / 3  (400.0%)\n",
      "Starting trial #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 3.0 / 1  (300.0):   0%|                                                                                   | 0/3 [00:06<?, ?it/s]\u001b[A\n",
      "Average Metric: 3.0 / 1  (300.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:06<00:12,  6.26s/it]\u001b[A\n",
      "Average Metric: 7.0 / 2  (350.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:12<00:12,  6.26s/it]\u001b[A\n",
      "Average Metric: 7.0 / 2  (350.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2/3 [00:12<00:06,  6.30s/it]\u001b[A\n",
      "Average Metric: 10.2 / 3  (340.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2/3 [00:17<00:06,  6.30s/it]\u001b[A\n",
      "Average Metric: 10.2 / 3  (340.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:17<00:00,  5.85s/it]\u001b[A\n",
      "[I 2024-03-28 21:38:59,918] Trial 2 finished with value: 340.0 and parameters: {'6090912784_predictor_instruction': 3, '6090912784_predictor_demos': 0}. Best is trial 1 with value: 400.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.2 / 3  (340.0%)\n",
      "Starting trial #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 3.8 / 1  (380.0):   0%|                                                                                   | 0/3 [00:05<?, ?it/s]\u001b[A\n",
      "Average Metric: 3.8 / 1  (380.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:05<00:11,  6.00s/it]\u001b[A\n",
      "Average Metric: 7.8 / 2  (390.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:11<00:11,  6.00s/it]\u001b[A\n",
      "Average Metric: 7.8 / 2  (390.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 2/3 [00:11<00:05,  5.60s/it]\u001b[A\n",
      "Average Metric: 11.8 / 3  (393.3):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2/3 [00:16<00:05,  5.60s/it]\u001b[A\n",
      "Average Metric: 11.8 / 3  (393.3): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:16<00:00,  5.63s/it]\u001b[A\n",
      "[I 2024-03-28 21:39:16,822] Trial 3 finished with value: 393.33 and parameters: {'6090912784_predictor_instruction': 9, '6090912784_predictor_demos': 3}. Best is trial 1 with value: 400.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.8 / 3  (393.3%)\n",
      "Starting trial #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 3.2 / 1  (320.0):   0%|                                                                                   | 0/3 [00:05<?, ?it/s]\u001b[A\n",
      "Average Metric: 3.2 / 1  (320.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                  | 1/3 [00:05<00:10,  5.18s/it]\u001b[A\n",
      "Average Metric: 6.800000000000001 / 2  (340.0):  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                        | 1/3 [00:11<00:10,  5.18s/it]\u001b[A\n",
      "Average Metric: 6.800000000000001 / 2  (340.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 2/3 [00:11<00:06,  6.14s/it]\u001b[A\n",
      "Average Metric: 10.8 / 3  (360.0):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 2/3 [00:15<00:06,  6.14s/it]\u001b[A\n",
      "Average Metric: 10.8 / 3  (360.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:15<00:00,  5.30s/it]\u001b[A\n",
      "[I 2024-03-28 21:39:32,747] Trial 4 finished with value: 360.0 and parameters: {'6090912784_predictor_instruction': 8, '6090912784_predictor_demos': 4}. Best is trial 1 with value: 400.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.8 / 3  (360.0%)\n",
      "Returning generate_answer = Predict(StringSignature(context, question -> answer\n",
      "    instructions=\"Observations: The provided observations indicate a need for the model to understand and interpret technical details, focusing on specific aspects to craft a clear, detailed response. The task requires an understanding of the role of various algorithms and their interactions. \\n\\nExamples: \\n\\n- Context: [Insert technical details and background information on algorithms]\\nQuestion: What is the function of X in Y algorithm? \\nAnswer: X is responsible for Z, which contributes to the overall goal of Q. \\n\\nBasic Instruction: Assess the context and answer the question. \\n\\nProposed Instruction: Analyze the technical intricacies and focus on the interplay of algorithms. Explain the role of the queried element, X, within the Y algorithm's mechanism, providing a concise yet detailed response.\"\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'Helpful information for answering the question.', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'A detailed answer that is supported by the context.', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      "))\n",
      "trial_logs[0][program].generate_answer = Predict(StringSignature(context, question -> answer\n",
      "    instructions='Observations: The dataset consists of specialized information on technical subjects, indicating the requirement for a sophisticated AI assistant to cater to researchers or developers. The focus should be on delivering concise and detailed responses that highlight specific elements. The target audience is professionals in scientific or technical fields.\\n\\nExamples:\\nQuestion: What are the advantages of vector databases over vector libraries in certain applications?\\n\\nAnswer: Vector databases offer a significant advantage over vector libraries in applications that demand real-time updates and scalable semantic search. Unlike vector libraries, vector databases allow for index data updates in real-time, making them more suitable for applications with dynamic data requirements. This feature ensures that the data remains current and enables efficient searching and retrieval.\\n\\nBasic Instruction: Assess the context and provide a clear, concise answer, focusing on the key differences between vector databases and libraries. \\n\\nProposed Instruction: Explain the limitations of vector libraries and the advantages of vector databases for real-time, scalable applications, emphasizing the immutability of index data and the importance of real-time updates. Provide a concise and technical comparison between the two, highlighting the key factors that influence their suitability in different contexts.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'Helpful information for answering the question.', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'A detailed answer that is supported by the context.', '__dspy_field_type': 'output', 'prefix': 'Vector libraries are indeed useful, but they have a major limitation in terms of real-time functionality. Vector databases offer a solution by providing‚Ä¶'})\n",
      "))\n",
      "trial_logs[1][program].generate_answer = Predict(StringSignature(context, question -> answer\n",
      "    instructions=\"Observations: The provided observations indicate a need for the model to understand and interpret technical details, focusing on specific aspects to craft a clear, detailed response. The task requires an understanding of the role of various algorithms and their interactions. \\n\\nExamples: \\n\\n- Context: [Insert technical details and background information on algorithms]\\nQuestion: What is the function of X in Y algorithm? \\nAnswer: X is responsible for Z, which contributes to the overall goal of Q. \\n\\nBasic Instruction: Assess the context and answer the question. \\n\\nProposed Instruction: Analyze the technical intricacies and focus on the interplay of algorithms. Explain the role of the queried element, X, within the Y algorithm's mechanism, providing a concise yet detailed response.\"\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'Helpful information for answering the question.', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'A detailed answer that is supported by the context.', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      "))\n",
      "trial_logs[2][program].generate_answer = Predict(StringSignature(context, question -> answer\n",
      "    instructions='Observations: The dataset consists of specialized information on technical subjects, indicating the requirement for a sophisticated AI assistant to cater to researchers or developers. The focus should be on delivering concise and detailed responses that highlight specific elements. The target audience is professionals in scientific or technical fields.\\n\\nExamples:\\nQuestion: What are the advantages of vector databases over vector libraries in certain applications?\\n\\nAnswer: Vector databases offer a key advantage over vector libraries when it comes to real-time updates and scalability. Unlike vector libraries, vector databases allow for real-time updates, making them suitable for applications that require scalable semantic search at the production level. This feature ensures that the data remains up-to-date and enables efficient processing of millions of objects.\\n\\nBasic Instruction: Assess the context and provide an answer.\\n\\nProposed Instruction: Explain the limitations of vector libraries in the context of real-time applications and emphasize the advantages of vector databases. Outline the professional setting this applies to.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'Helpful information for answering the question.', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'A detailed answer that is supported by the context.', '__dspy_field_type': 'output', 'prefix': 'For the following scenario, please describe the issues with vector libraries regarding real-time updates and recommend the suitable solution, keeping in mind the target audience of practitioners in scientific and technical fields:'})\n",
      "))\n",
      "trial_logs[3][program].generate_answer = Predict(StringSignature(context, question -> answer\n",
      "    instructions=\"Observations: The provided observations indicate a need for the model to understand and interpret technical details, focusing on specific aspects to craft a clear, detailed response. The task requires an understanding of the role of various algorithms and their interactions. \\n\\nExamples: \\n\\n- Context: [Insert technical details and background information on algorithms]\\nQuestion: What is the function of X in Y algorithm? \\nAnswer: X is responsible for Z, which contributes to the overall goal of Q. \\n\\nBasic Instruction: Assess the context and answer the question. \\n\\nProposed Instruction: Analyze the technical intricacies and focus on the interplay of algorithms. Explain the role of the queried element, X, within the Y algorithm's mechanism, providing a clear, concise response.\"\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'Helpful information for answering the question.', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'A detailed answer that is supported by the context.', '__dspy_field_type': 'output', 'prefix': 'Answer: The queried element, X, plays a role as a/the ...\" \\n\\nThis approach should help the model understand the requirement for a detailed and focused response, emphasizing the specific elements requested in the technical context.'})\n",
      "))\n",
      "trial_logs[4][program].generate_answer = Predict(StringSignature(context, question -> answer\n",
      "    instructions='Observations are on point and I don\\'t need any more detail for now. Here\\'s the optimized instruction along with a helpful prefix for the output field:\\n\\nProposed Instruction: Produce a clear, detailed answer to the posed question, focusing on the specified elements within the given context.\\n\\nPrefix for Output Field: \"Answer:'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'Helpful information for answering the question.', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'A detailed answer that is supported by the context.', '__dspy_field_type': 'output', 'prefix': 'That seems like a reasonable summary of the observations, yes! \\n\\nHere\\'s a shot at optimizing the instructions and output field prefix based on the provided information:\\n\\nProposed Instruction:\\n\\nProvide a concise and accurate response to the posed question, leveraging the provided context. The focus should be on clarity and specificity, aligning with the technical nature of the content. \\n\\nConsider the context and aim for an output that assists professional users in a scientific or technical realm. \\n\\nProposed Prefix For Output Field: \\n\\n\"Clarified Answer: \" \\n\\nThis prefix aims to indicate the desire for a precise and insightful answer, guiding the language model towards a more concise and technically focused response.'})\n",
      ")) from continue_program\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                     | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, display_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, display_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m MIPRO_compiled_RAG \u001b[38;5;241m=\u001b[39m teleprompter\u001b[38;5;241m.\u001b[39mcompile(RAG(), trainset\u001b[38;5;241m=\u001b[39mtrainset[:\u001b[38;5;241m3\u001b[39m], num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, max_bootstrapped_demos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_labeled_demos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, eval_kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m----> 6\u001b[0m eval_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMIPRO_compiled_RAG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_score)\n",
      "File \u001b[0;32m~/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:160\u001b[0m, in \u001b[0;36mEvaluate.__call__\u001b[0;34m(self, program, metric, devset, num_threads, display_progress, display_table, display, return_all_scores, return_outputs)\u001b[0m\n\u001b[1;32m    157\u001b[0m devset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(devset))\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_threads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_single_thread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapped_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_multi_thread(\n\u001b[1;32m    164\u001b[0m         wrapped_program,\n\u001b[1;32m    165\u001b[0m         devset,\n\u001b[1;32m    166\u001b[0m         num_threads,\n\u001b[1;32m    167\u001b[0m         display_progress,\n\u001b[1;32m    168\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:61\u001b[0m, in \u001b[0;36mEvaluate._execute_single_thread\u001b[0;34m(self, wrapped_program, devset, display_progress)\u001b[0m\n\u001b[1;32m     58\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(devset), dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m                  disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m display_progress)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, arg \u001b[38;5;129;01min\u001b[39;00m devset:\n\u001b[0;32m---> 61\u001b[0m     example_idx, example, prediction, score \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     reordered_devset\u001b[38;5;241m.\u001b[39mappend((example_idx, example, prediction, score))\n\u001b[1;32m     63\u001b[0m     ncorrect \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[0;32m~/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:150\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m    148\u001b[0m     current_error_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_count\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_error_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_errors:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError for example in dev set: \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m example_idx, example, \u001b[38;5;28mdict\u001b[39m(), \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/GitHub/recipes/integrations/dspy/myenv/lib/python3.11/site-packages/dspy_ai-2.4.1-py3.11.egg/dspy/evaluate/evaluate.py:133\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m program(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexample\u001b[38;5;241m.\u001b[39minputs())\n\u001b[0;32m--> 133\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# FIXME: TODO: What's the right order? Maybe force name-based kwargs!\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# increment assert and suggest failures to program's attributes\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(program, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_assert_failures\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import MIPRO\n",
    "\n",
    "teleprompter = MIPRO(prompt_model=command_r, task_model=command_r, metric=MetricWrapper, num_candidates=10, init_temperature=0)\n",
    "kwargs = dict(num_threads=1, display_progress=True, display_table=0)\n",
    "MIPRO_compiled_RAG = teleprompter.compile(RAG(), trainset=trainset[:3], num_trials=5, max_bootstrapped_demos=1, max_labeled_demos=0, eval_kwargs=kwargs)\n",
    "eval_score = evaluate(MIPRO_compiled_RAG, devset=devset, **kwargs)\n",
    "print(eval_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MIPRO_compiled_RAG(question=\"What is ref2vec?\").answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command_r.inspect_history(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
